{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqEncoder(d2l.Encoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "    def forward(self, X, *args):\n",
    "        X.shape\n",
    "        \n",
    "        X = self.embedding(X)\n",
    "        print(X.size)\n",
    "        X = X.permute(1, 0, 2)\n",
    "        print(X.size)\n",
    "        output, state = self.rnn(X)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x1058ebc70>\n",
      "<built-in method size of Tensor object at 0x1520b3950>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 16])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Seq2SeqEncoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "encoder.eval()\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "output, state = encoder(X)\n",
    "output.shape\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(d2l.Decoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0, **kwargs):\n",
    "        super(Seq2SeqDecoder, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "                          dropout=dropout)\n",
    "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
    "    def init_state(self, enc_outputs, *args):\n",
    "        return enc_outputs[1]\n",
    "    \n",
    "    def forward(self, X, state):\n",
    "        X = self.embedding(X)\n",
    "        print(X.size)\n",
    "        X = X.permute(1, 0, 2)\n",
    "        print(X.size)\n",
    "        context = state[-1].repeat(X.shape[0], 1, 1)\n",
    "        X_and_context = torch.cat((X, context), 2)\n",
    "        print(X_and_context)\n",
    "        output, state = self.rnn(X_and_context, state)\n",
    "        print(output)\n",
    "        output = self.dense(output).permute(1, 0, 2)\n",
    "        print(output)\n",
    "        return output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x15204b4a0>\n",
      "<built-in method size of Tensor object at 0x15204be00>\n",
      "<built-in method size of Tensor object at 0x1058d7040>\n",
      "<built-in method size of Tensor object at 0x15204be00>\n",
      "tensor([[[ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04]],\n",
      "\n",
      "        [[ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04]],\n",
      "\n",
      "        [[ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04]],\n",
      "\n",
      "        [[ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04]],\n",
      "\n",
      "        [[ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04]],\n",
      "\n",
      "        [[ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04]],\n",
      "\n",
      "        [[ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04],\n",
      "         [ 1.2138e+00,  8.9872e-01,  4.4591e-01, -1.1194e+00,  5.8268e-01,\n",
      "           2.0145e-01,  4.4862e-01,  3.1424e-01, -4.6463e-01, -3.8785e-03,\n",
      "           2.0352e-01, -1.9595e-01, -1.8877e-01,  2.8554e-02,  2.0585e-01,\n",
      "          -1.7636e-01,  3.1060e-01, -3.3057e-01,  2.5305e-01,  1.6652e-01,\n",
      "           2.1164e-01,  2.5128e-01, -8.1989e-02, -8.4802e-04]]],\n",
      "       grad_fn=<CatBackward0>)\n",
      "tensor([[[-0.2916,  0.0196,  0.0710, -0.1662, -0.1126, -0.0373, -0.0581,\n",
      "          -0.2111,  0.1013, -0.2951, -0.0040,  0.0319,  0.1014,  0.1189,\n",
      "          -0.0365,  0.1054],\n",
      "         [-0.2916,  0.0196,  0.0710, -0.1662, -0.1126, -0.0373, -0.0581,\n",
      "          -0.2111,  0.1013, -0.2951, -0.0040,  0.0319,  0.1014,  0.1189,\n",
      "          -0.0365,  0.1054],\n",
      "         [-0.2916,  0.0196,  0.0710, -0.1662, -0.1126, -0.0373, -0.0581,\n",
      "          -0.2111,  0.1013, -0.2951, -0.0040,  0.0319,  0.1014,  0.1189,\n",
      "          -0.0365,  0.1054],\n",
      "         [-0.2916,  0.0196,  0.0710, -0.1662, -0.1126, -0.0373, -0.0581,\n",
      "          -0.2111,  0.1013, -0.2951, -0.0040,  0.0319,  0.1014,  0.1189,\n",
      "          -0.0365,  0.1054]],\n",
      "\n",
      "        [[-0.1941, -0.0088, -0.0587, -0.0423, -0.0588, -0.1436, -0.2085,\n",
      "          -0.1646,  0.0868, -0.3192, -0.0776, -0.1201,  0.0702,  0.0155,\n",
      "          -0.0790,  0.2286],\n",
      "         [-0.1941, -0.0088, -0.0587, -0.0423, -0.0588, -0.1436, -0.2085,\n",
      "          -0.1646,  0.0868, -0.3192, -0.0776, -0.1201,  0.0702,  0.0155,\n",
      "          -0.0790,  0.2286],\n",
      "         [-0.1941, -0.0088, -0.0587, -0.0423, -0.0588, -0.1436, -0.2085,\n",
      "          -0.1646,  0.0868, -0.3192, -0.0776, -0.1201,  0.0702,  0.0155,\n",
      "          -0.0790,  0.2286],\n",
      "         [-0.1941, -0.0088, -0.0587, -0.0423, -0.0588, -0.1436, -0.2085,\n",
      "          -0.1646,  0.0868, -0.3192, -0.0776, -0.1201,  0.0702,  0.0155,\n",
      "          -0.0790,  0.2286]],\n",
      "\n",
      "        [[-0.1424, -0.0405, -0.1545,  0.0799, -0.0223, -0.2383, -0.3089,\n",
      "          -0.1232,  0.1357, -0.3725, -0.0975, -0.2321,  0.0855, -0.0711,\n",
      "          -0.1294,  0.3133],\n",
      "         [-0.1424, -0.0405, -0.1545,  0.0799, -0.0223, -0.2383, -0.3089,\n",
      "          -0.1232,  0.1357, -0.3725, -0.0975, -0.2321,  0.0855, -0.0711,\n",
      "          -0.1294,  0.3133],\n",
      "         [-0.1424, -0.0405, -0.1545,  0.0799, -0.0223, -0.2383, -0.3089,\n",
      "          -0.1232,  0.1357, -0.3725, -0.0975, -0.2321,  0.0855, -0.0711,\n",
      "          -0.1294,  0.3133],\n",
      "         [-0.1424, -0.0405, -0.1545,  0.0799, -0.0223, -0.2383, -0.3089,\n",
      "          -0.1232,  0.1357, -0.3725, -0.0975, -0.2321,  0.0855, -0.0711,\n",
      "          -0.1294,  0.3133]],\n",
      "\n",
      "        [[-0.1163, -0.0659, -0.2126,  0.1703,  0.0040, -0.3057, -0.3743,\n",
      "          -0.0972,  0.1932, -0.4285, -0.1013, -0.3009,  0.1137, -0.1418,\n",
      "          -0.1717,  0.3602],\n",
      "         [-0.1163, -0.0659, -0.2126,  0.1703,  0.0040, -0.3057, -0.3743,\n",
      "          -0.0972,  0.1932, -0.4285, -0.1013, -0.3009,  0.1137, -0.1418,\n",
      "          -0.1717,  0.3602],\n",
      "         [-0.1163, -0.0659, -0.2126,  0.1703,  0.0040, -0.3057, -0.3743,\n",
      "          -0.0972,  0.1932, -0.4285, -0.1013, -0.3009,  0.1137, -0.1418,\n",
      "          -0.1717,  0.3602],\n",
      "         [-0.1163, -0.0659, -0.2126,  0.1703,  0.0040, -0.3057, -0.3743,\n",
      "          -0.0972,  0.1932, -0.4285, -0.1013, -0.3009,  0.1137, -0.1418,\n",
      "          -0.1717,  0.3602]],\n",
      "\n",
      "        [[-0.1034, -0.0854, -0.2427,  0.2286,  0.0228, -0.3477, -0.4138,\n",
      "          -0.0825,  0.2405, -0.4744, -0.1004, -0.3383,  0.1396, -0.1961,\n",
      "          -0.2043,  0.3820],\n",
      "         [-0.1034, -0.0854, -0.2427,  0.2286,  0.0228, -0.3477, -0.4138,\n",
      "          -0.0825,  0.2405, -0.4744, -0.1004, -0.3383,  0.1396, -0.1961,\n",
      "          -0.2043,  0.3820],\n",
      "         [-0.1034, -0.0854, -0.2427,  0.2286,  0.0228, -0.3477, -0.4138,\n",
      "          -0.0825,  0.2405, -0.4744, -0.1004, -0.3383,  0.1396, -0.1961,\n",
      "          -0.2043,  0.3820],\n",
      "         [-0.1034, -0.0854, -0.2427,  0.2286,  0.0228, -0.3477, -0.4138,\n",
      "          -0.0825,  0.2405, -0.4744, -0.1004, -0.3383,  0.1396, -0.1961,\n",
      "          -0.2043,  0.3820]],\n",
      "\n",
      "        [[-0.0971, -0.1004, -0.2557,  0.2635,  0.0358, -0.3715, -0.4359,\n",
      "          -0.0747,  0.2739, -0.5077, -0.0984, -0.3561,  0.1591, -0.2352,\n",
      "          -0.2281,  0.3902],\n",
      "         [-0.0971, -0.1004, -0.2557,  0.2635,  0.0358, -0.3715, -0.4359,\n",
      "          -0.0747,  0.2739, -0.5077, -0.0984, -0.3561,  0.1591, -0.2352,\n",
      "          -0.2281,  0.3902],\n",
      "         [-0.0971, -0.1004, -0.2557,  0.2635,  0.0358, -0.3715, -0.4359,\n",
      "          -0.0747,  0.2739, -0.5077, -0.0984, -0.3561,  0.1591, -0.2352,\n",
      "          -0.2281,  0.3902],\n",
      "         [-0.0971, -0.1004, -0.2557,  0.2635,  0.0358, -0.3715, -0.4359,\n",
      "          -0.0747,  0.2739, -0.5077, -0.0984, -0.3561,  0.1591, -0.2352,\n",
      "          -0.2281,  0.3902]],\n",
      "\n",
      "        [[-0.0938, -0.1119, -0.2597,  0.2835,  0.0442, -0.3838, -0.4472,\n",
      "          -0.0709,  0.2958, -0.5299, -0.0965, -0.3631,  0.1725, -0.2618,\n",
      "          -0.2447,  0.3924],\n",
      "         [-0.0938, -0.1119, -0.2597,  0.2835,  0.0442, -0.3838, -0.4472,\n",
      "          -0.0709,  0.2958, -0.5299, -0.0965, -0.3631,  0.1725, -0.2618,\n",
      "          -0.2447,  0.3924],\n",
      "         [-0.0938, -0.1119, -0.2597,  0.2835,  0.0442, -0.3838, -0.4472,\n",
      "          -0.0709,  0.2958, -0.5299, -0.0965, -0.3631,  0.1725, -0.2618,\n",
      "          -0.2447,  0.3924],\n",
      "         [-0.0938, -0.1119, -0.2597,  0.2835,  0.0442, -0.3838, -0.4472,\n",
      "          -0.0709,  0.2958, -0.5299, -0.0965, -0.3631,  0.1725, -0.2618,\n",
      "          -0.2447,  0.3924]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-0.2722, -0.0951, -0.0256, -0.0143, -0.1987,  0.1288,  0.0588,\n",
      "           0.2867,  0.0863, -0.1280],\n",
      "         [-0.1567, -0.0756, -0.0899, -0.0315, -0.2275,  0.0969,  0.0470,\n",
      "           0.2713,  0.1374, -0.1780],\n",
      "         [-0.0811, -0.0613, -0.1492, -0.0252, -0.2719,  0.0820,  0.0571,\n",
      "           0.2654,  0.1707, -0.2294],\n",
      "         [-0.0363, -0.0484, -0.1903, -0.0121, -0.3117,  0.0795,  0.0723,\n",
      "           0.2674,  0.1913, -0.2678],\n",
      "         [-0.0116, -0.0360, -0.2144,  0.0006, -0.3414,  0.0822,  0.0862,\n",
      "           0.2730,  0.2035, -0.2930],\n",
      "         [ 0.0015, -0.0248, -0.2268,  0.0104, -0.3616,  0.0861,  0.0970,\n",
      "           0.2791,  0.2101, -0.3084],\n",
      "         [ 0.0081, -0.0157, -0.2324,  0.0174, -0.3745,  0.0894,  0.1048,\n",
      "           0.2842,  0.2133, -0.3176]],\n",
      "\n",
      "        [[-0.2722, -0.0951, -0.0256, -0.0143, -0.1987,  0.1288,  0.0588,\n",
      "           0.2867,  0.0863, -0.1280],\n",
      "         [-0.1567, -0.0756, -0.0899, -0.0315, -0.2275,  0.0969,  0.0470,\n",
      "           0.2713,  0.1374, -0.1780],\n",
      "         [-0.0811, -0.0613, -0.1492, -0.0252, -0.2719,  0.0820,  0.0571,\n",
      "           0.2654,  0.1707, -0.2294],\n",
      "         [-0.0363, -0.0484, -0.1903, -0.0121, -0.3117,  0.0795,  0.0723,\n",
      "           0.2674,  0.1913, -0.2678],\n",
      "         [-0.0116, -0.0360, -0.2144,  0.0006, -0.3414,  0.0822,  0.0862,\n",
      "           0.2730,  0.2035, -0.2930],\n",
      "         [ 0.0015, -0.0248, -0.2268,  0.0104, -0.3616,  0.0861,  0.0970,\n",
      "           0.2791,  0.2101, -0.3084],\n",
      "         [ 0.0081, -0.0157, -0.2324,  0.0174, -0.3745,  0.0894,  0.1048,\n",
      "           0.2842,  0.2133, -0.3176]],\n",
      "\n",
      "        [[-0.2722, -0.0951, -0.0256, -0.0143, -0.1987,  0.1288,  0.0588,\n",
      "           0.2867,  0.0863, -0.1280],\n",
      "         [-0.1567, -0.0756, -0.0899, -0.0315, -0.2275,  0.0969,  0.0470,\n",
      "           0.2713,  0.1374, -0.1780],\n",
      "         [-0.0811, -0.0613, -0.1492, -0.0252, -0.2719,  0.0820,  0.0571,\n",
      "           0.2654,  0.1707, -0.2294],\n",
      "         [-0.0363, -0.0484, -0.1903, -0.0121, -0.3117,  0.0795,  0.0723,\n",
      "           0.2674,  0.1913, -0.2678],\n",
      "         [-0.0116, -0.0360, -0.2144,  0.0006, -0.3414,  0.0822,  0.0862,\n",
      "           0.2730,  0.2035, -0.2930],\n",
      "         [ 0.0015, -0.0248, -0.2268,  0.0104, -0.3616,  0.0861,  0.0970,\n",
      "           0.2791,  0.2101, -0.3084],\n",
      "         [ 0.0081, -0.0157, -0.2324,  0.0174, -0.3745,  0.0894,  0.1048,\n",
      "           0.2842,  0.2133, -0.3176]],\n",
      "\n",
      "        [[-0.2722, -0.0951, -0.0256, -0.0143, -0.1987,  0.1288,  0.0588,\n",
      "           0.2867,  0.0863, -0.1280],\n",
      "         [-0.1567, -0.0756, -0.0899, -0.0315, -0.2275,  0.0969,  0.0470,\n",
      "           0.2713,  0.1374, -0.1780],\n",
      "         [-0.0811, -0.0613, -0.1492, -0.0252, -0.2719,  0.0820,  0.0571,\n",
      "           0.2654,  0.1707, -0.2294],\n",
      "         [-0.0363, -0.0484, -0.1903, -0.0121, -0.3117,  0.0795,  0.0723,\n",
      "           0.2674,  0.1913, -0.2678],\n",
      "         [-0.0116, -0.0360, -0.2144,  0.0006, -0.3414,  0.0822,  0.0862,\n",
      "           0.2730,  0.2035, -0.2930],\n",
      "         [ 0.0015, -0.0248, -0.2268,  0.0104, -0.3616,  0.0861,  0.0970,\n",
      "           0.2791,  0.2101, -0.3084],\n",
      "         [ 0.0081, -0.0157, -0.2324,  0.0174, -0.3745,  0.0894,  0.1048,\n",
      "           0.2842,  0.2133, -0.3176]]], grad_fn=<PermuteBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 16])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size=10, embed_size=8, num_hiddens=16,\n",
    "                         num_layers=2)\n",
    "decoder.eval()\n",
    "state = decoder.init_state(encoder(X))\n",
    "output, state = decoder(X, state)\n",
    "output.shape\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_mask(X, valid_len, value=0):\n",
    "    maxlen = X.size(1)\n",
    "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                        device=X.device)[None, :] < valid_len[:, None]\n",
    "    X[~mask] = value\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [4, 5, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "sequence_mask(X, torch.tensor([1, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.],\n",
       "         [-1., -1., -1., -1.]],\n",
       "\n",
       "        [[ 1.,  1.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  1.],\n",
       "         [-1., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones(2, 3, 4)\n",
    "sequence_mask(X, torch.tensor([1, 2]), value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
    "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
    "    def forward(self, pred, label, valid_len):\n",
    "        weights = torch.ones_like(label)\n",
    "        weights = sequence_mask(weights, valid_len)\n",
    "        self.reduction='none'\n",
    "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n",
    "            pred.permute(0, 2, 1), label)\n",
    "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
    "        return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3026, 1.1513, 0.0000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = MaskedSoftmaxCELoss()\n",
    "loss(torch.ones(3, 4, 10), torch.ones((3, 4), dtype=torch.long),\n",
    "     torch.tensor([4, 2, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
    "    def xavier_init_weights(m):\n",
    "        if type(m) == nn.Linear:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        if type(m) == nn.GRU:\n",
    "            for param in m._flat_weights_names:\n",
    "                if \"weight\" in param:\n",
    "                    nn.init.xavier_uniform_(m._parameters[param])\n",
    "    net.apply(xavier_init_weights)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss = MaskedSoftmaxCELoss()\n",
    "    net.train()\n",
    "    animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
    "                            xlim=[10, num_epochs])\n",
    "    for epoch in range(num_epochs):\n",
    "        timer = d2l.Timer()\n",
    "        metric = d2l.Accumulator(2)\n",
    "        for batch in data_iter:\n",
    "            optimizer.zero_grad()\n",
    "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
    "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0],\n",
    "                               device=device).reshape(-1, 1)\n",
    "            dec_input = torch.cat([bos, Y[:, :-1]], 1)\n",
    "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
    "            l = loss(Y_hat, Y, Y_valid_len)\n",
    "            l.sum().backward()\n",
    "            d2l.grad_clipping(net, 1)\n",
    "            num_tokens = Y_valid_len.sum()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l.sum(), num_tokens)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            animator.add(epoch + 1, (metric[0] / metric[1], ))\n",
    "    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f}'\n",
    "          f'tokens/sec on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 300, d2l.try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, src_vocab, tgt_vocab = d2l.load_data_nmt(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderDecoder(\n",
      "  (encoder): Seq2SeqEncoder(\n",
      "    (embedding): Embedding(184, 32)\n",
      "    (rnn): GRU(32, 32, num_layers=2, dropout=0.1)\n",
      "  )\n",
      "  (decoder): Seq2SeqDecoder(\n",
      "    (embedding): Embedding(201, 32)\n",
      "    (rnn): GRU(64, 32, num_layers=2, dropout=0.1)\n",
      "    (dense): Linear(in_features=32, out_features=201, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
    "net = d2l.EncoderDecoder(encoder, decoder)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.019, 14478.7tokens/sec on cpu\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"262.1875pt\" height=\"183.35625pt\" viewBox=\"0 0 262.1875 183.35625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-08-21T14:28:35.935844</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 183.35625 \n",
       "L 262.1875 183.35625 \n",
       "L 262.1875 -0 \n",
       "L 0 -0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.14375 145.8 \n",
       "L 245.44375 145.8 \n",
       "L 245.44375 7.2 \n",
       "L 50.14375 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 77.081681 145.8 \n",
       "L 77.081681 7.2 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m189a694f50\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m189a694f50\" x=\"77.081681\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 50 -->\n",
       "      <g transform=\"translate(70.719181 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 110.754095 145.8 \n",
       "L 110.754095 7.2 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m189a694f50\" x=\"110.754095\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(101.210345 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 144.426509 145.8 \n",
       "L 144.426509 7.2 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m189a694f50\" x=\"144.426509\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 150 -->\n",
       "      <g transform=\"translate(134.882759 160.398438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 178.098922 145.8 \n",
       "L 178.098922 7.2 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m189a694f50\" x=\"178.098922\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(168.555172 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 211.771336 145.8 \n",
       "L 211.771336 7.2 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m189a694f50\" x=\"211.771336\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 250 -->\n",
       "      <g transform=\"translate(202.227586 160.398438)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 245.44375 145.8 \n",
       "L 245.44375 7.2 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m189a694f50\" x=\"245.44375\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(235.9 160.398438)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- epoch -->\n",
       "     <g transform=\"translate(132.565625 174.076563)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \n",
       "L 1159 -1331 \n",
       "L 581 -1331 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2969 \n",
       "Q 1341 3281 1617 3432 \n",
       "Q 1894 3584 2278 3584 \n",
       "Q 2916 3584 3314 3078 \n",
       "Q 3713 2572 3713 1747 \n",
       "Q 3713 922 3314 415 \n",
       "Q 2916 -91 2278 -91 \n",
       "Q 1894 -91 1617 61 \n",
       "Q 1341 213 1159 525 \n",
       "z\n",
       "M 3116 1747 \n",
       "Q 3116 2381 2855 2742 \n",
       "Q 2594 3103 2138 3103 \n",
       "Q 1681 3103 1420 2742 \n",
       "Q 1159 2381 1159 1747 \n",
       "Q 1159 1113 1420 752 \n",
       "Q 1681 391 2138 391 \n",
       "Q 2594 391 2855 752 \n",
       "Q 3116 1113 3116 1747 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \n",
       "L 3122 2828 \n",
       "Q 2878 2963 2633 3030 \n",
       "Q 2388 3097 2138 3097 \n",
       "Q 1578 3097 1268 2742 \n",
       "Q 959 2388 959 1747 \n",
       "Q 959 1106 1268 751 \n",
       "Q 1578 397 2138 397 \n",
       "Q 2388 397 2633 464 \n",
       "Q 2878 531 3122 666 \n",
       "L 3122 134 \n",
       "Q 2881 22 2623 -34 \n",
       "Q 2366 -91 2075 -91 \n",
       "Q 1284 -91 818 406 \n",
       "Q 353 903 353 1747 \n",
       "Q 353 2603 823 3093 \n",
       "Q 1294 3584 2113 3584 \n",
       "Q 2378 3584 2631 3529 \n",
       "Q 2884 3475 3122 3366 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-65\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-70\" x=\"61.523438\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"125\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-63\" x=\"186.181641\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"241.162109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 50.14375 119.340316 \n",
       "L 245.44375 119.340316 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <defs>\n",
       "       <path id=\"m4f35ecf06d\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4f35ecf06d\" x=\"50.14375\" y=\"119.340316\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.05 -->\n",
       "      <g transform=\"translate(20.878125 123.139535)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 50.14375 86.477956 \n",
       "L 245.44375 86.477956 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4f35ecf06d\" x=\"50.14375\" y=\"86.477956\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.10 -->\n",
       "      <g transform=\"translate(20.878125 90.277175)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 50.14375 53.615596 \n",
       "L 245.44375 53.615596 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4f35ecf06d\" x=\"50.14375\" y=\"53.615596\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0.15 -->\n",
       "      <g transform=\"translate(20.878125 57.414815)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 50.14375 20.753236 \n",
       "L 245.44375 20.753236 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4f35ecf06d\" x=\"50.14375\" y=\"20.753236\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 0.20 -->\n",
       "      <g transform=\"translate(20.878125 24.552455)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_12\">\n",
       "     <!-- loss -->\n",
       "     <g transform=\"translate(14.798437 86.157813)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-6c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 50.14375 13.5 \n",
       "L 56.878233 54.329825 \n",
       "L 63.612716 77.690809 \n",
       "L 70.347198 93.953396 \n",
       "L 77.081681 105.438186 \n",
       "L 83.816164 113.081153 \n",
       "L 90.550647 119.27068 \n",
       "L 97.285129 122.803742 \n",
       "L 104.019612 126.970185 \n",
       "L 110.754095 129.035894 \n",
       "L 117.488578 131.7051 \n",
       "L 124.22306 132.493104 \n",
       "L 130.957543 134.542033 \n",
       "L 137.692026 135.258849 \n",
       "L 144.426509 135.290932 \n",
       "L 151.160991 136.482444 \n",
       "L 157.895474 137.273394 \n",
       "L 164.629957 137.567147 \n",
       "L 171.36444 137.73982 \n",
       "L 178.098922 138.306168 \n",
       "L 184.833405 138.21856 \n",
       "L 191.567888 138.516572 \n",
       "L 198.302371 138.133253 \n",
       "L 205.036853 138.988563 \n",
       "L 211.771336 139.098848 \n",
       "L 218.505819 138.990764 \n",
       "L 225.240302 138.962049 \n",
       "L 231.974784 138.981927 \n",
       "L 238.709267 139.364187 \n",
       "L 245.44375 139.5 \n",
       "\" clip-path=\"url(#p6035b6ba14)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.14375 145.8 \n",
       "L 50.14375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 245.44375 145.8 \n",
       "L 245.44375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.14375 145.8 \n",
       "L 245.44375 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.14375 7.2 \n",
       "L 245.44375 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p6035b6ba14\">\n",
       "   <rect x=\"50.14375\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seq2seq(net, src_sentence, src_vocab, tgt_cocab, num_steps,\n",
    "                    device, save_attention_weights=False):\n",
    "    net.eval()\n",
    "    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n",
    "        src_vocab['<eos>']]\n",
    "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
    "    src_tokens = d2l.truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
    "    enc_X = torch.unsqueeze(\n",
    "        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
    "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
    "    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
    "    dec_X = torch.unsqueeze(torch.tensor(\n",
    "        [tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
    "    output_seq, attention_weight_seq = [], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = net.decoder(dec_X, dec_state)\n",
    "        dec_X = Y.argmax(dim=2)\n",
    "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
    "        if save_attention_weights:\n",
    "            attention_weight_seq.append(net.decoder.attention_weights)\n",
    "        if pred == tgt_vocab['<eos>']:\n",
    "            break\n",
    "        output_seq.append(pred)\n",
    "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu(pred_seq, label_seq, k):\n",
    "    \"\"\"Compute the BLEU.\"\"\"\n",
    "    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\n",
    "fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x1525464f0>\n",
      "<built-in method size of Tensor object at 0x152546e00>\n",
      "<built-in method size of Tensor object at 0x152546d60>\n",
      "<built-in method size of Tensor object at 0x152546a90>\n",
      "tensor([[[ 0.8106, -0.6988,  0.0032,  0.0862, -1.2587, -0.6633,  0.2425,\n",
      "           0.4189,  0.1711,  0.1278, -0.4198, -2.2580, -0.0491,  0.3116,\n",
      "          -1.7015, -1.4841, -1.0343,  1.1245,  0.9093, -0.2917,  0.1858,\n",
      "          -0.4663,  0.8404, -0.0680, -0.8339,  0.4894, -0.0552, -1.0674,\n",
      "          -0.5742, -0.0080,  1.4084,  0.8964, -0.1008, -1.0000, -1.0000,\n",
      "          -0.8474,  0.7471,  0.6608, -0.9964, -0.9999, -1.0000, -0.4858,\n",
      "          -0.9788, -0.9981,  1.0000,  1.0000, -0.8257,  1.0000,  1.0000,\n",
      "           1.0000, -0.9894,  1.0000,  1.0000,  1.0000, -0.8702, -1.0000,\n",
      "          -1.0000,  1.0000,  0.9848, -0.9982,  0.9776,  0.9972, -0.8819,\n",
      "          -0.9991]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9995,  0.9678, -0.9992, -0.8474, -0.9781,  0.6623,  0.9301,\n",
      "          -1.0000,  0.8988, -0.4858, -0.9787,  0.9907,  0.9998, -0.9986,\n",
      "          -0.9999,  0.9999, -0.9997, -0.9994, -0.9894,  0.9185,  1.0000,\n",
      "           1.0000, -0.9852, -1.0000, -1.0000,  0.1277,  0.9801, -0.9981,\n",
      "          -0.9291,  0.9897, -0.8822, -0.9487]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[  6.8276,  -1.2819,  -1.4183,  -4.2934,  -8.2040,  -0.6907,  -3.7601,\n",
      "           -0.5423,   6.4925, -10.3706,   5.5288,   4.2958,  -0.4955,  -1.5042,\n",
      "           -1.9607,   1.5345,  16.5568,  -1.1249,   0.6140,   2.1167,   6.0414,\n",
      "           -0.2252,   1.0438,   6.6628,   1.4690,  -4.3671,   6.0305,  -4.8457,\n",
      "           -0.5212,  -2.9154,   6.5111,  -3.3433,  -2.9948,  -0.7801,  -4.4740,\n",
      "            0.8087,   3.3484,  -1.6798,  -4.4581,  -0.1584,   0.4783,   1.8208,\n",
      "            1.7320,   6.9632,  -3.7561,   5.5941,   4.0929,  -4.0458,  -1.9550,\n",
      "           10.8715,   1.6491,   0.8361,  -1.0263,  -8.8740,  -4.6375,   0.4107,\n",
      "            0.1632,   1.8400,  -1.8803,  13.0226,  -4.6912,  -0.9634,  -4.3523,\n",
      "            1.5312,   0.1092,   5.7628,   2.8496,   7.7043,  -2.2693,   3.3172,\n",
      "            5.3870,   2.9790,   0.9036,   9.6791,  -4.6651,   1.1227,   1.5238,\n",
      "            1.1198,   7.8823,  -1.2902,   8.4417,   8.6164,   1.9355,   2.1429,\n",
      "           -1.5975,  -2.1652,  -5.2143,   5.9451,   0.0819,   1.2263,   1.5975,\n",
      "            4.0505,   4.0088,   2.5294,   3.1976,   2.8393,   5.5443,   0.2653,\n",
      "           -2.7448,   2.8386,   2.0818,  -3.3855,  -3.1022,  -4.8357,  -1.1271,\n",
      "           -4.3814,  -2.3170,  -6.7996,  -7.8799,  -3.3699,   0.7741,  -1.5541,\n",
      "           -6.8535,   9.1656,   1.0027,   3.7883,  -2.1713,   2.5034,   0.8162,\n",
      "            0.4574,   3.9454,   6.7387,   5.4869,   0.7004,  -1.3955,  -1.9815,\n",
      "           -1.3639,  -1.2921,   3.2878,  -1.4573,   0.7168,  -1.7582,  -5.5376,\n",
      "           -3.6437,  -1.4911,  -7.3260,  -3.1021, -13.8663,  -3.2622,  -5.1612,\n",
      "           -0.6308,  -5.8306,   8.1451,  -3.9209,  -4.6267,  -4.6132,  -4.5127,\n",
      "            3.4918,   4.9944,   4.7639,  -2.7522,   4.7218,  -4.4969,   1.5032,\n",
      "            3.8349,   2.5219,   0.8016,  -1.4880,   0.2945,   0.0305,   2.8023,\n",
      "           -3.2080,   1.1340,  -3.7814,  -5.0004,  -4.2317,  -1.2391,  -6.2192,\n",
      "           -3.7981,  -3.2531,  -2.9747,   7.5096,   5.4404,   5.4767,  -3.4923,\n",
      "            3.0208,   0.1324,   2.8246,   0.3858,   0.4508,  -5.4974,  -2.1467,\n",
      "           -4.1500,   5.6939,   2.3675,   2.0799,   3.4057,   1.9319,  -4.1968,\n",
      "           -9.2761,   0.2735,   0.1102,  -0.5917,   2.5554,   1.8877,   7.1962,\n",
      "            3.3885,   6.8312,   0.3525,  -1.1864,  -1.3827]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x169842950>\n",
      "<built-in method size of Tensor object at 0x152555400>\n",
      "tensor([[[-0.4387, -0.6726,  0.2183,  0.1770, -1.7405,  0.6926,  0.9922,\n",
      "           1.0621,  0.0800,  0.4704, -0.6692,  0.2952,  0.0835,  0.6486,\n",
      "           0.4841,  1.7772,  0.1489,  1.2693, -0.3598, -1.3230, -1.3841,\n",
      "           1.3140, -0.5774,  0.7238,  0.0758, -0.2244, -1.2037, -0.0573,\n",
      "          -0.8956,  0.8684,  0.7372,  0.0845,  0.9995,  0.9678, -0.9992,\n",
      "          -0.8474, -0.9781,  0.6623,  0.9301, -1.0000,  0.8988, -0.4858,\n",
      "          -0.9787,  0.9907,  0.9998, -0.9986, -0.9999,  0.9999, -0.9997,\n",
      "          -0.9994, -0.9894,  0.9185,  1.0000,  1.0000, -0.9852, -1.0000,\n",
      "          -1.0000,  0.1277,  0.9801, -0.9981, -0.9291,  0.9897, -0.8822,\n",
      "          -0.9487]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9996, -0.9933, -0.9992, -0.8525,  0.2453,  0.9998, -0.6904,\n",
      "          -0.9998,  0.9180, -0.4858, -0.2032,  0.9966,  0.9901, -0.6591,\n",
      "           0.9185,  0.5853,  0.9327, -0.9907, -0.9436, -0.9996,  1.0000,\n",
      "          -0.9558,  0.8786, -0.9997, -1.0000, -0.9845, -0.9983, -0.9573,\n",
      "          -1.0000, -0.7833, -0.9080,  0.9763]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ 8.1853e+00, -3.4848e+00, -3.0548e+00,  1.6006e+00,  2.0499e+00,\n",
      "           1.1866e+01, -9.9130e+00, -3.9311e-01,  5.7899e+00, -4.7530e+00,\n",
      "          -3.4894e+00,  1.5585e+00, -4.3641e-01, -6.1247e+00,  2.2714e+00,\n",
      "           7.3626e-01,  9.4735e-01, -4.0537e+00, -9.0654e+00,  4.9101e+00,\n",
      "          -3.2823e-01, -4.9323e+00,  3.8273e+00,  2.1837e+00, -6.6519e+00,\n",
      "          -1.5545e+00, -2.6009e-02, -4.4756e+00,  1.3224e+00,  2.8727e+00,\n",
      "           4.6175e+00,  2.6993e-01,  5.8171e+00, -2.1966e+00, -2.5267e+00,\n",
      "          -2.1081e+00,  7.4628e+00, -6.9787e-02, -7.2008e+00,  1.8555e-01,\n",
      "           3.7857e+00, -2.2100e+00,  4.7204e+00,  6.1135e+00, -3.0777e+00,\n",
      "           8.1856e+00,  1.4637e+00,  1.1861e+00,  1.0948e+00,  7.6237e-01,\n",
      "           4.9767e+00,  2.1526e+00, -3.3731e+00, -9.8372e-01,  5.0344e+00,\n",
      "          -4.5716e-02, -3.5571e+00,  1.0904e+00,  7.1866e-01,  2.0773e+00,\n",
      "          -6.7373e+00, -2.4029e+00, -2.4399e+00, -9.9984e+00, -5.7923e+00,\n",
      "           4.6038e-01, -3.1456e+00,  3.5902e-02,  1.6292e+00,  5.7315e+00,\n",
      "           1.3053e+00,  7.5557e-02,  7.1479e+00,  3.0520e+00, -1.6280e+00,\n",
      "          -7.3415e+00, -6.7841e+00, -4.1211e+00,  1.8600e+00, -9.8686e+00,\n",
      "           2.1966e+00,  2.7199e+00,  1.7162e+00,  1.8558e-01, -1.7691e+00,\n",
      "          -5.2383e+00, -9.5787e-01, -3.0666e+00, -9.2680e-01, -5.7005e+00,\n",
      "          -2.2724e+00,  4.2424e+00,  4.5069e+00, -2.0726e+00, -1.3940e+00,\n",
      "          -1.6217e+00, -4.5357e+00, -7.0223e+00, -1.0159e+00, -1.3923e+00,\n",
      "           5.4645e+00, -2.9169e+00, -2.6135e+00,  1.5737e+00,  2.4399e+00,\n",
      "          -7.2147e-01, -1.9692e+00, -8.3261e+00, -7.6178e+00, -4.4067e+00,\n",
      "           1.7331e+00, -3.5952e+00, -3.0027e+00,  5.8762e+00,  1.1701e+00,\n",
      "           3.1401e+00,  6.0267e+00,  3.8163e+00,  1.1106e+00, -3.0288e+00,\n",
      "           2.1465e+00,  1.8881e+00,  4.5509e-01,  7.1626e+00, -2.7033e+00,\n",
      "           1.5680e+00, -3.1417e+00, -3.1838e+00,  5.4832e+00, -1.1950e-01,\n",
      "          -1.2239e+00, -4.4149e+00,  1.1565e-03, -1.7371e+00, -1.6171e+00,\n",
      "          -5.9830e+00, -7.2696e+00, -7.2732e+00, -1.4212e+00, -4.6302e+00,\n",
      "           4.1546e+00, -2.5992e+00,  1.6188e+00, -2.4576e+00, -3.1483e+00,\n",
      "          -2.6612e+00, -2.6477e+00, -5.3435e+00, -2.0321e+00, -1.6877e+00,\n",
      "          -5.8546e+00,  7.3576e-01, -3.6585e+00,  3.5285e+00,  1.3183e+00,\n",
      "          -4.7067e+00, -3.2626e+00,  3.8074e+00,  5.5635e-01, -1.5483e+00,\n",
      "          -8.8933e-01, -1.6836e+00, -3.5024e+00, -6.6599e+00, -6.9557e+00,\n",
      "          -6.4191e+00, -8.0210e+00, -7.7140e+00, -1.4609e+00, -3.5426e+00,\n",
      "          -1.2751e+00, -7.4458e-01,  1.5229e-01, -6.0879e-02, -2.1245e+00,\n",
      "          -3.7614e+00,  3.0285e+00, -4.5160e+00,  2.9332e+00, -7.0864e-01,\n",
      "          -4.5021e+00, -1.0573e+00, -4.9151e+00, -4.2599e+00,  4.0772e+00,\n",
      "           4.3993e+00,  1.8518e+00,  1.8342e+00, -2.2908e+00, -1.0627e+01,\n",
      "           4.6193e+00, -2.7449e+00, -2.8470e+00,  2.4091e+00,  3.0928e+00,\n",
      "           1.8522e+00,  6.6848e+00, -2.5382e+00,  4.1385e-01, -4.9486e+00,\n",
      "          -6.2524e-01]]], grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x152389400>\n",
      "<built-in method size of Tensor object at 0x152555a40>\n",
      "tensor([[[ 1.1238,  1.7262,  0.0249, -0.7439, -3.3730,  0.0784,  0.3110,\n",
      "          -1.3353,  0.1329, -1.7313, -0.1858, -0.3109, -0.1719,  0.7674,\n",
      "           0.1907, -0.5730,  0.0677, -0.6451,  1.4529,  0.6272,  1.0016,\n",
      "          -1.5191, -0.5513, -1.1390, -0.8000, -2.0530, -0.1848,  2.3105,\n",
      "          -1.2605,  1.2305, -2.0519, -0.2332,  0.9996, -0.9933, -0.9992,\n",
      "          -0.8525,  0.2453,  0.9998, -0.6904, -0.9998,  0.9180, -0.4858,\n",
      "          -0.2032,  0.9966,  0.9901, -0.6591,  0.9185,  0.5853,  0.9327,\n",
      "          -0.9907, -0.9436, -0.9996,  1.0000, -0.9558,  0.8786, -0.9997,\n",
      "          -1.0000, -0.9845, -0.9983, -0.9573, -1.0000, -0.7833, -0.9080,\n",
      "           0.9763]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9996,  0.9708, -0.9989,  0.9997,  0.9945,  0.9946, -0.9967,\n",
      "          -0.9998,  0.5743,  0.1198, -0.9987,  0.8553, -0.9989,  0.4807,\n",
      "           0.9995,  0.7726,  0.9995,  0.9923, -0.9746, -1.0000, -0.9447,\n",
      "          -0.9345,  0.9914,  0.9094, -0.8250, -0.3701, -0.0062, -0.9949,\n",
      "          -0.8604,  0.9911,  0.9943,  0.8983]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ -0.1304,  -1.6197,  -1.1106,  17.1069,   5.1664,   4.0669,  -5.1408,\n",
      "          -10.6996,   2.0560,   4.0013,  -0.6031,   2.5385,  -0.1545,  -4.1489,\n",
      "            7.0938,  -0.9828,   0.0894,   1.4672,  -4.6520,  -0.7026,  -2.6388,\n",
      "           -1.4166,   4.1535,  -3.3749, -10.8983,   0.9513,  -4.4137,  -4.2529,\n",
      "           -1.0517,  -8.4193,   6.9221,   4.9587,  -1.8017,  -1.8882,   3.1779,\n",
      "           -4.7198,  -7.8360,  -6.9771,  -8.1116,  -4.0392,   0.1615,  -4.8496,\n",
      "           -3.0511,   1.2604,  -3.5029,   1.0034,  -1.7220,   0.4958,  -3.1819,\n",
      "           -2.6530,  -1.4240,   3.0023,   0.3177,  -3.5534,  10.2813,   2.7761,\n",
      "           -3.6481,  -4.6035,  -1.2240,  -0.1400,   0.1053,  -5.5804,  -4.3274,\n",
      "           -6.5433,  -8.2472,   2.5626,  -4.9848,  -3.7354,  -0.4815,  -2.7826,\n",
      "           -1.8648,  -2.7693,   2.4654,  -0.5737,  -5.7035,  -6.1052,  -6.6380,\n",
      "            2.7567,   0.1101,  -8.4994,   0.2054,   0.3720,  -2.8162,   4.5567,\n",
      "           -5.8105,   1.3956,  -1.5797,  -8.1612,  -1.5921,  -8.6247,  -5.9333,\n",
      "           -2.5569,  -2.6126,  -4.7917,   0.3347,   0.6137,  -3.7377,  -1.8725,\n",
      "            2.3581,   1.4476,   0.5550,  -3.8187,  -4.5320,  -1.6282,   0.2440,\n",
      "            6.8386,   2.3322,   1.1423,  -3.7243,   3.0378,   2.5863,  -3.1778,\n",
      "            2.0065,   3.6117,   0.3936,   1.9387,   1.4212,  -1.9836,  -1.7774,\n",
      "           -3.8415,  -1.7193,  -1.2594,  -3.0633,   1.5334,   3.4478,   4.9457,\n",
      "           -3.8957,  -3.2939,  -0.3573,  -1.0500,  -3.0164,  -4.5748,   1.2184,\n",
      "            2.6611,   0.9355,  -0.9185,  -2.4286,   0.5720,   2.2906,  -6.4031,\n",
      "           -2.3833,   7.7071,   0.1318,  -3.3625,  -2.8937,  -2.7409,  -2.9852,\n",
      "           -7.4691,  -1.4012,  -1.2889,   0.9488,  -7.3080,   0.9117,   0.2673,\n",
      "            0.1784,  -4.1353,  -8.7124,   6.3899,   1.9513,  -2.6645,   0.8821,\n",
      "            0.1998,  -1.6209,  -1.3335,  -0.8087,  -1.2950,  -1.2750,  -4.8969,\n",
      "           -0.2623,  -9.4321,  -6.0909,  -7.7214,  -6.9898,  -6.7466,   7.6653,\n",
      "           -3.9653,  -4.8996,  -4.8058,  -4.9797,   5.6856,  -1.5254,  -3.3844,\n",
      "           -5.7717,  -0.7752,   3.7248,   7.4239,  -3.3542,  -2.7672,  -3.7062,\n",
      "            3.2931,   0.9671,  -2.1564,  -2.7220,  -0.3912,   8.3168,  -1.7077,\n",
      "           -1.2997,  -2.9131,  -1.1725,  -5.6647,  -2.1201]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "go . => va !,  bleu 1.000\n",
      "<built-in method size of Tensor object at 0x117de7ea0>\n",
      "<built-in method size of Tensor object at 0x15238dbd0>\n",
      "<built-in method size of Tensor object at 0x152555ea0>\n",
      "<built-in method size of Tensor object at 0x152555400>\n",
      "tensor([[[ 0.8106, -0.6988,  0.0032,  0.0862, -1.2587, -0.6633,  0.2425,\n",
      "           0.4189,  0.1711,  0.1278, -0.4198, -2.2580, -0.0491,  0.3116,\n",
      "          -1.7015, -1.4841, -1.0343,  1.1245,  0.9093, -0.2917,  0.1858,\n",
      "          -0.4663,  0.8404, -0.0680, -0.8339,  0.4894, -0.0552, -1.0674,\n",
      "          -0.5742, -0.0080,  1.4084,  0.8964, -0.9987, -0.9998, -0.9999,\n",
      "           1.0000,  0.9999, -0.9988, -0.9978, -0.9793, -0.9999, -0.9987,\n",
      "          -0.9990, -0.9997,  0.5726,  0.9986,  0.9571,  1.0000,  0.9999,\n",
      "           0.9987, -1.0000,  0.4007,  1.0000, -0.8623, -0.9990, -0.9999,\n",
      "          -1.0000,  1.0000,  0.8636,  0.9870, -0.9948, -0.9999, -0.0751,\n",
      "          -0.9986]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9969,  0.9998, -0.7528,  0.9998, -0.2668, -0.9988,  0.9961,\n",
      "           0.9996,  0.9999, -0.9987, -0.9988,  0.9878,  0.9980, -0.9861,\n",
      "          -0.9995,  0.9766,  0.9641, -0.5728, -0.9997,  0.5104,  1.0000,\n",
      "          -0.5361, -0.9994, -0.9999, -0.9999,  1.0000,  1.0000,  0.9870,\n",
      "           0.9927, -0.9998, -0.2789, -0.9997]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[  5.5405,  -1.4802,  -1.2650,  -4.5484, -11.8098,  -6.5651,  10.3107,\n",
      "           -6.7003,   3.4886,  -3.5057,  12.9266,   6.8013,   3.4077,   4.9219,\n",
      "           -1.7611,  -3.7243,   7.2789,  -0.4478,   2.7037,   0.6694,   7.9683,\n",
      "            6.4876,  -3.8743,   7.2002,   2.6735,   8.3042,   6.6683,   3.0849,\n",
      "           -0.9248,   4.5197,   4.6098,   1.1403,  -2.0096,  -2.0710,  -0.3950,\n",
      "            0.5644,   5.5256,  -1.6599,   2.6567,   0.0407,   2.8457,   1.3294,\n",
      "            4.4070,   3.5072,   4.3588,   3.4693,  -1.4424,  -1.5444,   4.8022,\n",
      "            5.4584,   3.3403,  -1.9665,   2.1326,  -7.0314,  -6.1654,  -8.6916,\n",
      "            3.8612,  -4.4705,  -3.3881,   1.4349,   2.0498,  -1.0679,  -1.8541,\n",
      "           -1.3454,   1.8200,   1.8101,   4.2916,  -2.1490,  -9.0249,   5.6253,\n",
      "           -2.1292,  -3.4462,   1.7435,   2.8406,  -1.2493,   4.8888,   4.6964,\n",
      "           -0.8516,   2.0792,  -1.8475,   6.3372,   6.4518,   1.5813,  -0.6562,\n",
      "           -0.6081,   1.0573,  -3.9879,   7.0901,  -3.1658,   2.0242,   6.7031,\n",
      "            1.2417,   1.5733,   4.5481,   6.2634,   5.7700,  -2.5008,  -1.4176,\n",
      "           -3.9718,  -7.0850,  -8.7656,   7.2992,   1.3378,  -5.3307,  -4.2371,\n",
      "          -12.4460,   4.4352,  -4.2193,  -5.6974,   2.8423,   0.0546,   2.2942,\n",
      "           -7.9904,   4.2562,  -0.2795,   4.6100,  -3.4065,   2.9602,  -0.4901,\n",
      "           -2.1261,  -0.1779,  -4.0208,  -2.5801,   3.2886,  -1.4505,  -5.5587,\n",
      "            4.0601,   3.9942,   2.4207,   1.3927,  -0.5315,  -6.9180,   2.2402,\n",
      "            0.3044,   1.1919,  -2.6790,   1.7085,  -7.8802,  -0.0510,  -4.4226,\n",
      "            2.2310,  -4.8309,   0.8788,  -2.5365,  -2.8779,  -3.1347,  -2.6407,\n",
      "            5.0866,  -3.9738,  -4.0548,  -1.4824,   0.3226,  -3.2353,  -0.1302,\n",
      "           -1.1042,  -3.0359,   3.7984,  -5.5779,   1.8211,   2.5202,  -0.3677,\n",
      "            1.4484,  -0.0841,   0.4449,   0.1317,   0.0828,  -2.4307,   1.4363,\n",
      "           -3.4293,   6.3440,   0.0359,   0.5298,   5.7415,   5.4120,  -1.8845,\n",
      "            6.6204,   1.1136,   6.3122,   1.6928,   2.6426,  -2.2387,   2.1439,\n",
      "           -0.7553,   1.3582,  -4.0416,  -0.0555,  -1.2096,  -4.0443,  -8.3731,\n",
      "           -5.0671,  -1.1950,  -4.8116,  -4.6942,   2.3401,   0.9406,   0.4986,\n",
      "           -0.0589,   3.1027,   0.5175,   2.4604,   1.5447]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x152389400>\n",
      "<built-in method size of Tensor object at 0x152555ea0>\n",
      "tensor([[[ 1.8083,  0.1390,  0.4391, -0.6165, -0.7874, -1.4117,  2.7264,\n",
      "          -1.3520, -1.4656,  0.7927,  0.8147, -1.4543, -1.7791, -0.0474,\n",
      "          -0.0541, -1.7336, -0.2197, -0.9494, -0.4368, -0.1472, -0.3949,\n",
      "           1.6958,  0.2205, -0.1290, -0.5248, -1.2018,  0.4980, -2.7810,\n",
      "           1.2849, -0.8167,  0.9607, -0.6257,  0.9969,  0.9998, -0.7528,\n",
      "           0.9998, -0.2668, -0.9988,  0.9961,  0.9996,  0.9999, -0.9987,\n",
      "          -0.9988,  0.9878,  0.9980, -0.9861, -0.9995,  0.9766,  0.9641,\n",
      "          -0.5728, -0.9997,  0.5104,  1.0000, -0.5361, -0.9994, -0.9999,\n",
      "          -0.9999,  1.0000,  1.0000,  0.9870,  0.9927, -0.9998, -0.2789,\n",
      "          -0.9997]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9977, -0.6526,  0.9229,  0.9998, -0.9993, -0.9397,  0.3471,\n",
      "           0.9968,  0.9960, -0.9987,  0.6924, -0.9172,  0.9991,  0.0675,\n",
      "          -1.0000, -0.9987, -0.9545, -0.0828, -0.9977,  0.1060,  1.0000,\n",
      "          -0.9938, -1.0000, -0.9999, -1.0000, -0.9777, -0.9999,  0.9873,\n",
      "          -0.9978, -0.9806, -0.3652, -0.9995]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[  9.2121,  -2.8446,  -3.1692,  -5.7922,  -7.5513,  -4.7836,   2.4120,\n",
      "            1.9093,  -3.4678,  -1.7279,   2.7905,  -2.2160,   0.4925,   3.9813,\n",
      "            0.3331,   3.6250,   3.5296,   0.8873,   0.4261,   2.4507,   1.5972,\n",
      "           -1.9634,  -2.7454,   6.2720,   1.2536,  12.0150,  -0.5417,   5.2975,\n",
      "           -1.3319,   7.5658, -10.4371,   1.6931,   1.3768,  -2.4278,   6.4631,\n",
      "           -2.1603,  10.6962,   5.0930,  -1.5209,   5.1061,   6.0671,  -2.3088,\n",
      "            5.8621,   5.4867,   8.8031,   5.0246,   3.2777,   3.0767,  12.6183,\n",
      "           -1.9430,   4.0129,   2.6691,  -1.1979,   2.3556,  -6.0919,  -3.2332,\n",
      "            8.7366,  -4.6839,   2.1790,  -1.7913,  -2.3891,   5.0987,   3.4300,\n",
      "           -3.1706,   1.7099,  -2.7584,   5.3272,  -1.4053, -10.0470,   7.2572,\n",
      "           -9.5293,  -2.1462,  -6.0269,  -2.7811,  -2.8013,   3.8208,   4.0684,\n",
      "           -3.9886,  -0.4067,  -3.0169,  -4.5389,  -4.3428,  -0.6419,  -3.3925,\n",
      "           -0.6249,   0.9783,  -0.2065,  -1.7213,  -1.0540,   1.9782,  -3.8313,\n",
      "            1.1346,   1.3215,   5.8539,  -0.3420,  -0.8322,  -0.4260,   2.3326,\n",
      "           -5.7548,  -5.2278,  -5.0864,   5.9350,   9.0957,  -1.0050,  -2.8617,\n",
      "          -13.1120,   3.1448,  -6.6223,  -4.0229,  -1.0523,   0.4500,  -0.8728,\n",
      "           -0.4560,  -1.7036,  -1.6583,   2.7064,   2.6973,   7.9406,   4.2687,\n",
      "           -6.4639,  -0.4092,  -5.9435,  -3.4986,   0.9170,  -4.7469,  -9.7286,\n",
      "           -3.3748,  -4.2162,   3.6563,  -1.9723,   5.0554,  -1.4903,   2.9022,\n",
      "           -0.4031,  -7.5282,  -0.4512,   2.7078,   2.1059,  -3.2623,  -1.6485,\n",
      "            0.1525,  -4.3557,  -0.8950,   0.1039,  -0.2752,  -0.3618,  -0.3080,\n",
      "            3.0113,  -3.3014,  -2.5936,  -2.4836,   0.6561,  -2.8739,  -1.2090,\n",
      "            0.1725,  -1.7367,   6.8031,  -0.2126,  -1.5148,   6.5397,  -3.6788,\n",
      "            3.2969,  -5.7233,   1.7092,   1.2465,   1.1942,  -3.7203,   2.4799,\n",
      "           -2.8596,   7.8669,   5.3674,  -5.4782,   6.9133,   7.1216,  -6.2602,\n",
      "           -0.7192,   4.5294,  -0.7051,   4.8579,  -1.7294,   0.0539,  -0.1230,\n",
      "            0.4107,  -2.0846,  -2.5585,  -6.5487,  -2.1181,  -0.2855,   1.7813,\n",
      "           -5.0301,   0.4400,  -2.2335,  -2.0530,  -0.2907,  -4.5893,   0.6891,\n",
      "           -0.9198,  -8.7753,   1.5165,   4.7710,  -4.4765]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x15251af40>\n",
      "<built-in method size of Tensor object at 0x152378770>\n",
      "tensor([[[-1.3559, -0.2719, -1.1217, -1.7592, -2.4342,  0.3145, -0.9331,\n",
      "          -0.2333,  0.7815, -0.3666,  1.2840,  1.0845,  1.0177,  0.6684,\n",
      "           1.1721,  0.2037, -1.1708, -2.1875, -1.2673,  0.2520, -0.3100,\n",
      "          -1.7025, -0.6711, -0.2525,  0.1689,  1.5070,  0.4752, -0.2230,\n",
      "           0.1973,  0.9801,  0.7852, -1.3896,  0.9977, -0.6526,  0.9229,\n",
      "           0.9998, -0.9993, -0.9397,  0.3471,  0.9968,  0.9960, -0.9987,\n",
      "           0.6924, -0.9172,  0.9991,  0.0675, -1.0000, -0.9987, -0.9545,\n",
      "          -0.0828, -0.9977,  0.1060,  1.0000, -0.9938, -1.0000, -0.9999,\n",
      "          -1.0000, -0.9777, -0.9999,  0.9873, -0.9978, -0.9806, -0.3652,\n",
      "          -0.9995]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9921, -0.9946,  0.6101, -0.9892, -0.3990,  0.8585,  0.9711,\n",
      "           0.9948, -0.6307,  0.8730,  1.0000, -0.9997, -1.0000,  0.8713,\n",
      "           0.9730,  0.9012,  0.7094, -0.2738, -0.9997, -0.9559, -0.9913,\n",
      "          -0.9935,  0.4179,  0.9979, -0.9902, -0.1649, -0.9768, -0.9333,\n",
      "          -0.9688, -0.9995,  0.9545,  0.5698]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[  5.9863,  -3.7034,  -4.1244,   5.8878,  16.7497,   6.4904,  -4.0801,\n",
      "           -3.8716,  -3.6087,  10.3444,  -4.2729,  -2.0092,  -0.4384,  -4.4441,\n",
      "            1.2213,   4.8323,  -1.7198,   5.6493,  -1.1447,   6.1509,  -7.8943,\n",
      "           -1.0726,   6.4330,  -2.1012,  -1.3122,   3.0876,  -9.5775,  -0.6995,\n",
      "            2.5323,   1.9357, -10.0606,   0.7072,   7.2726,   5.1839,   7.0153,\n",
      "           -6.7546,   0.4490,  -1.0590,  -5.6298,  -2.1781,  -2.8555,  -7.4205,\n",
      "            0.8908,   1.0807,   0.9094,  -2.6276,  -7.5063,   7.6940,   0.1810,\n",
      "           -9.0775,  -1.0610,   3.9523,  -4.8068,   4.0305,   0.2779,   2.5623,\n",
      "           -3.3163,   2.2735,  -1.3880,  -4.0770, -11.2709,  -3.7132,   0.1660,\n",
      "           -8.9339,  -6.8433,  -4.7628,  -9.0042,  -0.6178,  -2.5841,  -6.5959,\n",
      "           -6.9514,  -0.6144,  -0.6029,  -4.7942,  -4.5218, -11.0177, -10.8168,\n",
      "           -2.2859,  -5.2742,  -7.8184,  -4.5055,  -4.7316,  -2.9570,  -2.0866,\n",
      "           -6.6152,  -4.3000,  -1.5553,  -7.8563,   5.6947,  -6.7017,  -6.0206,\n",
      "           -0.3625,  -0.8371,  -7.6172,  -9.5386,  -8.5262,   0.9982,  -1.5070,\n",
      "            1.9592,   1.1793,  -0.2875,   0.1030,   2.7360,   0.3235,   5.2265,\n",
      "            2.2526,  -2.9720,  -1.1999,  -1.6639,   0.3748,  -0.7986,   0.6633,\n",
      "            2.0117,  -7.7990,  -0.4795,  -3.9226,  -3.3803,  -6.4331,  -1.5312,\n",
      "           -7.6856,  -1.2866,  -4.5835,  -2.5308,  -1.3641,  -0.5084,   1.7650,\n",
      "           -8.2901,  -8.2296,  -6.8692,  -7.2535,  -6.3452,  -2.7407,  -0.1024,\n",
      "            4.1338,   2.8433,   4.2505,   2.5364,   4.1118,  -1.8218,   0.4373,\n",
      "           -1.6413,   5.9574,  -5.0655,   0.8654,   1.3297,   1.2382,   0.7154,\n",
      "           -8.4035,  -2.2399,  -2.6174,  -1.2805,  -2.8186,  -1.4693,  -0.5994,\n",
      "           -1.3800,  -3.3938,  -3.8416,   1.5550,  -1.3133,  -9.4993,   0.9605,\n",
      "           -5.3081,   0.8695,  -3.6775,  -4.0823,  -3.8788,  -1.9264,  -0.9005,\n",
      "           -1.8494,  -8.3608,  -4.3784,  -9.8026,  -3.1242,  -3.3261,  -1.6542,\n",
      "           -8.4240,  -3.1025,  -8.7536,  -2.6713,  -1.9902,   0.7048,   1.1788,\n",
      "            0.1151,  -3.8144,  -2.1848,  -4.5218,  -7.6999,  -2.6677,   0.9889,\n",
      "            2.0711,  -0.3680,  -2.3469,  -1.6458,  -3.3273,  -0.1009,  -8.3791,\n",
      "           -7.8014,  -7.7430,   1.7113,  -2.6538,  -2.9983]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x16988c0e0>\n",
      "<built-in method size of Tensor object at 0x152378770>\n",
      "tensor([[[-1.2208,  0.9683, -1.4363,  1.9375, -0.9508,  1.3620,  0.0077,\n",
      "          -0.9960, -2.6099, -0.8484, -1.1518,  1.4891,  1.2493,  3.0472,\n",
      "           1.0534, -0.8887, -0.0725, -1.7192,  1.5008, -0.1137, -0.4895,\n",
      "          -0.0465, -1.2658, -1.0220, -1.7588, -1.2856,  1.6190,  1.6343,\n",
      "          -1.1993,  0.7814, -0.8043, -0.0160,  0.9921, -0.9946,  0.6101,\n",
      "          -0.9892, -0.3990,  0.8585,  0.9711,  0.9948, -0.6307,  0.8730,\n",
      "           1.0000, -0.9997, -1.0000,  0.8713,  0.9730,  0.9012,  0.7094,\n",
      "          -0.2738, -0.9997, -0.9559, -0.9913, -0.9935,  0.4179,  0.9979,\n",
      "          -0.9902, -0.1649, -0.9768, -0.9333, -0.9688, -0.9995,  0.9545,\n",
      "           0.5698]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9817,  0.9925,  0.6025,  1.0000,  0.9179,  0.9148, -0.9660,\n",
      "           0.9947, -0.6408,  0.9628, -0.9630, -0.9998, -1.0000,  0.8767,\n",
      "           1.0000,  0.9546,  0.9837,  0.9984, -0.9952, -0.9995, -0.9924,\n",
      "          -0.7021,  0.9973,  1.0000,  0.2314, -0.6970, -0.0328, -0.9997,\n",
      "          -0.9614,  0.9721,  1.0000,  0.5856]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ 1.7799e+00, -2.5397e+00, -2.7037e+00,  1.8232e+01,  8.2000e+00,\n",
      "           6.2777e-01, -1.1201e+00, -1.2265e+01, -5.6828e+00,  7.4202e+00,\n",
      "           1.0615e+00,  3.2708e+00, -1.9262e+00, -2.6661e+00,  5.9642e+00,\n",
      "           1.4581e+00, -3.0154e+00,  2.6804e+00,  5.3224e-01, -2.1248e+00,\n",
      "          -9.0765e+00,  2.2601e+00,  5.5760e+00, -7.5697e+00, -3.1384e+00,\n",
      "           4.6980e+00, -1.1277e+01,  1.5892e+00, -3.1203e+00, -6.9781e+00,\n",
      "          -3.3528e+00,  2.1908e+00, -1.0953e+00,  3.9981e+00,  3.8316e+00,\n",
      "          -6.8043e+00, -9.1840e+00, -7.4692e+00, -2.5907e+00, -2.1062e+00,\n",
      "          -5.7616e+00, -7.2618e+00,  6.6961e-02,  2.4632e+00, -2.5535e-01,\n",
      "          -4.3999e+00, -4.4526e+00,  1.3228e+00, -2.1182e+00, -7.5276e+00,\n",
      "          -5.5582e+00,  5.8608e+00, -1.2402e+00, -6.7304e-01,  7.4746e+00,\n",
      "           2.0579e-02,  2.5902e-01, -5.5944e-01, -3.1280e+00, -2.9185e+00,\n",
      "           1.0389e-01, -3.4206e+00, -2.4370e+00, -4.0450e+00, -7.5631e+00,\n",
      "           2.0375e-01, -7.1483e+00, -2.3637e+00, -1.4273e+00, -8.6197e+00,\n",
      "          -5.6854e+00, -3.1411e+00, -2.3053e+00, -4.8220e+00, -3.1558e+00,\n",
      "          -8.5412e+00, -8.9658e+00,  3.0852e+00, -5.0199e+00, -4.4705e+00,\n",
      "          -5.5900e+00, -5.3766e+00, -5.6236e+00,  4.9707e+00, -3.8926e+00,\n",
      "          -7.0681e-01, -7.8086e-01, -8.9850e+00, -2.1702e+00, -8.5621e+00,\n",
      "          -7.1342e+00, -6.6501e+00, -6.6624e+00, -7.5045e+00, -6.0299e+00,\n",
      "          -5.5629e+00,  1.2289e+00,  3.2109e+00,  2.4864e+00,  4.2671e+00,\n",
      "          -1.7315e+00,  3.8818e-01,  6.4914e-03,  2.8431e-01, -1.8856e+00,\n",
      "           5.9926e+00,  4.3229e+00,  4.5995e+00,  6.7283e-01,  2.0185e+00,\n",
      "           8.2164e-01,  2.8351e+00,  6.7735e+00, -4.9394e+00, -1.2320e+00,\n",
      "          -3.9880e+00, -2.9562e+00, -5.4012e+00, -2.5387e+00, -5.1504e+00,\n",
      "          -3.1542e+00, -5.0849e+00, -3.2987e+00,  1.8267e+00,  4.1540e+00,\n",
      "           6.8740e+00, -3.5048e+00, -3.1937e+00, -5.8141e+00, -5.0975e+00,\n",
      "          -1.2227e+00, -1.8165e+00, -7.0795e-01,  3.6585e+00,  1.9953e+00,\n",
      "           6.1673e-01, -8.9031e-01,  5.5122e+00,  2.3013e+00,  4.7496e-01,\n",
      "          -5.1767e+00,  5.1918e+00, -4.4428e+00, -1.0973e+00, -4.6002e-01,\n",
      "          -8.0205e-01, -8.2171e-01, -4.8811e+00, -1.1971e-01,  3.2302e-02,\n",
      "          -1.1706e+00, -9.2027e+00, -1.6326e-01, -3.5451e+00,  3.4725e-01,\n",
      "           7.5663e-01, -6.1666e+00,  3.3820e+00,  7.4644e-01, -3.7640e+00,\n",
      "           2.7570e+00, -1.0405e+00, -1.5388e+00, -1.9797e+00, -2.1200e+00,\n",
      "          -2.0370e+00,  2.9222e+00, -4.1499e+00,  1.0311e+00, -1.0340e+01,\n",
      "          -4.9883e+00, -1.2456e+01, -6.7555e+00, -6.5982e+00,  4.1552e+00,\n",
      "          -7.1712e+00, -7.5339e+00, -8.0537e+00, -7.4229e+00,  3.5347e+00,\n",
      "           1.4342e+00, -9.5676e-01, -4.0161e+00,  1.3749e-01,  2.2570e+00,\n",
      "           4.7644e+00, -8.7106e+00, -4.6267e+00, -2.4517e-01,  3.6555e+00,\n",
      "          -2.7306e-02, -1.5116e+00, -1.9024e+00, -5.4278e+00,  3.6145e-01,\n",
      "          -8.6611e+00, -6.2065e+00, -6.8595e+00,  7.8317e-01, -3.4562e+00,\n",
      "          -2.6408e+00]]], grad_fn=<PermuteBackward0>)\n",
      "i lost . => j'ai perdu .,  bleu 1.000\n",
      "<built-in method size of Tensor object at 0x169842900>\n",
      "<built-in method size of Tensor object at 0x169842950>\n",
      "<built-in method size of Tensor object at 0x152522180>\n",
      "<built-in method size of Tensor object at 0x152522590>\n",
      "tensor([[[ 0.8106, -0.6988,  0.0032,  0.0862, -1.2587, -0.6633,  0.2425,\n",
      "           0.4189,  0.1711,  0.1278, -0.4198, -2.2580, -0.0491,  0.3116,\n",
      "          -1.7015, -1.4841, -1.0343,  1.1245,  0.9093, -0.2917,  0.1858,\n",
      "          -0.4663,  0.8404, -0.0680, -0.8339,  0.4894, -0.0552, -1.0674,\n",
      "          -0.5742, -0.0080,  1.4084,  0.8964, -0.9658, -0.9998, -1.0000,\n",
      "           0.9997, -0.6361,  0.9992, -0.9973, -0.9991, -1.0000, -0.9258,\n",
      "          -1.0000, -0.9859,  0.9902,  0.9999, -0.4180,  0.9997,  0.9886,\n",
      "           0.8077,  0.7620,  0.8700,  0.9631,  0.9971, -0.9934, -1.0000,\n",
      "          -1.0000,  1.0000,  0.9622,  0.9991,  0.9996, -0.9945, -0.3886,\n",
      "          -0.9997]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9377,  0.9105, -0.9333,  0.9997, -0.9998,  0.9992,  0.9897,\n",
      "          -0.3920,  0.9966, -0.9258, -1.0000,  0.9951,  0.9988, -1.0000,\n",
      "          -0.9710, -0.9858, -0.9966, -0.9819,  0.7620,  0.9890,  0.9631,\n",
      "           0.9999, -0.9967, -1.0000, -1.0000,  0.9993,  0.9999,  0.9991,\n",
      "           0.9975, -0.9947, -0.3887, -0.9974]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ 3.0600e+00, -8.9099e-03,  3.7741e-01, -9.2141e+00, -1.3011e+01,\n",
      "          -5.4613e+00,  3.8124e+00,  5.8073e+00,  5.1976e+00, -7.2641e+00,\n",
      "           3.5000e+00,  8.7502e+00, -1.8625e+00,  7.9462e+00, -1.3574e+00,\n",
      "          -2.6304e+00,  7.7011e+00, -1.6205e+00,  9.9783e+00, -1.1295e-01,\n",
      "           1.3688e+01, -1.4105e+00, -7.7950e+00,  5.5395e+00,  6.6230e-01,\n",
      "           1.2377e+00,  1.5191e+01, -4.0879e+00, -5.6332e+00,  8.9434e-02,\n",
      "          -5.9367e-01, -1.6700e+00, -7.6678e+00, -4.6337e+00, -2.7145e+00,\n",
      "           1.2702e+00,  5.5694e+00, -2.2683e+00,  4.5675e+00,  2.2872e+00,\n",
      "           2.4748e+00,  2.4086e+00,  6.1857e+00,  2.8550e+00,  1.3643e+00,\n",
      "           4.1054e+00,  3.6463e+00, -2.1578e+00,  3.6960e+00,  8.1207e+00,\n",
      "           1.4594e+00, -8.8208e+00,  5.1554e+00, -9.2632e+00, -9.7231e+00,\n",
      "          -4.9339e-01,  1.4210e-01, -2.6463e+00,  9.4595e-01,  7.0765e+00,\n",
      "           4.2410e+00,  3.0347e+00,  2.4410e+00,  2.6350e+00,  7.7201e+00,\n",
      "          -8.7896e-01,  7.0390e+00,  4.3644e+00, -3.6621e+00,  5.7810e+00,\n",
      "           4.4443e+00, -2.9395e+00,  1.6607e+00,  6.8590e+00, -5.2341e+00,\n",
      "           7.7273e+00,  7.6283e+00,  4.2408e+00,  1.9480e+00,  4.8008e+00,\n",
      "           1.0187e+01,  1.0415e+01,  3.6832e+00, -8.7990e-01,  3.8377e+00,\n",
      "           3.2139e+00, -1.4130e+00,  6.6057e+00, -1.5430e+00,  7.8241e+00,\n",
      "           8.8210e+00,  3.8398e+00,  3.8506e+00,  6.0221e+00,  4.9238e+00,\n",
      "           4.4533e+00, -6.2267e-01, -1.2193e+00, -6.8231e+00, -2.6884e+00,\n",
      "          -1.9119e+00, -1.2050e+00, -2.9199e+00, -4.5874e+00, -3.2656e+00,\n",
      "          -1.2522e+01, -9.4423e-01, -6.0129e+00, -7.8213e+00, -1.3278e-01,\n",
      "           2.5238e-01,  1.6680e+00, -2.3833e+00,  2.9671e+00,  5.5297e-01,\n",
      "           4.9144e+00,  6.2137e-01,  5.4966e+00,  1.0319e+00,  1.4099e+00,\n",
      "          -1.8404e+00,  4.7184e+00,  4.9244e+00,  1.5739e+00, -5.2062e+00,\n",
      "          -5.3872e+00,  1.9305e+00,  2.0155e+00, -6.3640e-01, -1.7798e-02,\n",
      "           4.2910e+00, -4.1406e+00,  4.7838e-01, -4.3470e+00, -2.6277e+00,\n",
      "          -4.2272e+00,  1.4494e+00, -6.4632e+00,  1.1903e+00, -7.4341e+00,\n",
      "          -3.7449e-01, -5.0331e+00,  1.4706e+00, -9.4482e-01, -1.4390e+00,\n",
      "          -1.3440e+00, -1.1914e+00,  9.2154e+00, -9.7534e-01, -1.1848e+00,\n",
      "           1.1885e+00,  3.1714e+00, -2.1896e+00,  4.6808e+00, -2.2742e+00,\n",
      "           1.3862e+00,  4.2202e+00, -3.0242e+00, -1.2576e+00,  1.9783e+00,\n",
      "          -1.6208e+00,  2.2691e+00,  8.2682e-01,  8.4270e-01,  8.9935e-01,\n",
      "           3.4646e-01, -1.7350e+00,  2.0275e+00, -2.6623e+00,  5.7953e+00,\n",
      "           3.9355e+00,  6.7775e+00,  7.9347e+00,  7.6999e+00, -8.9511e-01,\n",
      "           1.2743e+01,  6.1780e+00,  1.2554e+01,  6.1795e+00,  6.8633e-01,\n",
      "          -3.6756e+00, -4.0715e+00,  1.9420e+00,  4.9895e+00,  5.7488e-01,\n",
      "          -4.2125e-02,  2.5426e+00, -2.7642e+00, -8.7508e+00, -7.4806e+00,\n",
      "          -6.2968e+00, -3.0929e+00, -3.2948e+00,  4.2214e+00,  2.1424e+00,\n",
      "           1.0551e+01,  6.1783e+00,  2.7107e+00,  6.0475e-01, -6.1360e-01,\n",
      "          -2.1368e+00]]], grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x152522590>\n",
      "<built-in method size of Tensor object at 0x152523db0>\n",
      "tensor([[[-0.1071,  0.5088, -1.8819, -0.5978, -1.1277,  0.8678,  0.1433,\n",
      "          -0.3446, -1.5132, -0.4441, -1.4287, -0.6868, -0.4317, -0.4341,\n",
      "          -1.8069,  0.2785,  0.6719, -0.5651,  2.1898,  1.1386, -0.2488,\n",
      "           0.1192,  1.8619,  0.2636,  0.0875, -1.6877, -0.6212, -0.4550,\n",
      "           0.1725, -0.4157,  0.2653, -1.4553,  0.9377,  0.9105, -0.9333,\n",
      "           0.9997, -0.9998,  0.9992,  0.9897, -0.3920,  0.9966, -0.9258,\n",
      "          -1.0000,  0.9951,  0.9988, -1.0000, -0.9710, -0.9858, -0.9966,\n",
      "          -0.9819,  0.7620,  0.9890,  0.9631,  0.9999, -0.9967, -1.0000,\n",
      "          -1.0000,  0.9993,  0.9999,  0.9991,  0.9975, -0.9947, -0.3887,\n",
      "          -0.9974]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9913, -0.5669,  0.8431,  0.9991, -1.0000,  0.9977, -0.9555,\n",
      "          -0.1524,  0.9883, -0.9257,  0.9186,  0.9369,  0.8019, -0.9999,\n",
      "          -0.9826, -0.9996, -1.0000,  0.9813,  0.7619, -0.9497,  0.9596,\n",
      "          -0.9914, -0.9971, -0.9911, -0.9999, -0.9796, -0.9927,  0.9673,\n",
      "          -0.9999, -0.9761, -0.4006,  0.9904]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[  8.6205,  -2.7009,  -2.2358,  -3.9599,  -8.1002,   0.4653,  -5.1697,\n",
      "            4.8928,  -1.6887,  -5.8789,  -4.0501,  -2.5693,  -1.5033,  -1.3736,\n",
      "            6.6623,   0.2359,  -2.3712,  -2.1226,  -1.0968,   3.0275,   2.1698,\n",
      "           -9.2687,  -1.3434,   5.0099,  -7.8863,   5.1153,   2.7553,  -5.2225,\n",
      "            4.1859,   5.5288,  -8.8222,   1.1383,   2.4713,  -5.8752,   3.1496,\n",
      "           -1.6900,  10.5283,   4.6677,  -2.5133,   6.5745,   8.1884,  -1.7436,\n",
      "            1.2635,   3.6718,   2.7406,   7.0532,   3.6249,   3.4375,   5.9150,\n",
      "           -1.4211,   8.3435,  -2.1604,   0.2421,   2.5597,  -3.0132,  -0.1566,\n",
      "            1.5099,  -5.0046,   9.8395,  -1.2920,   0.1319,   5.9071,   1.9464,\n",
      "           -3.2165,   5.2368,  -0.2887,   6.3462,  -5.6099,   0.8278,  10.2378,\n",
      "           -2.7103,  -1.9884,  -0.9125,  -2.2807,   0.4601,   3.7230,   3.7073,\n",
      "           -8.2150,  -0.2186,  -3.9721,  -2.6170,  -2.2570,   0.9311,  -4.0270,\n",
      "            0.3121,   4.5140,   6.2005,  -7.6131,   1.7229,   4.6522,  -5.8459,\n",
      "            0.9925,   1.0471,   5.9761,  -2.0983,  -2.6337,  -7.6777,  -2.0054,\n",
      "           -5.1284,  -3.1374,  -0.1162,  -1.2218,   3.4253,   1.2896,   0.5565,\n",
      "           -8.5944,   4.6856,  -4.0235,  -3.2072,   0.9426,   1.4323,  -3.8547,\n",
      "            4.5814,  -0.7015,   0.0556,   4.6313,  12.2204,  10.8034,   6.8997,\n",
      "           -0.9128,  -2.0845,   1.7219,   2.2739,  -0.2091,  -5.0044,  -7.7804,\n",
      "           -1.0693,  -1.5707,   3.1482,   2.0470,   4.9361,  -4.5554,   1.6437,\n",
      "           -1.7905,  -9.4172,  -0.5101,   3.0079,   5.0494,   1.3513,  -5.4701,\n",
      "            1.0449,  -1.1807,  -0.1551,  -1.3360,  -1.6135,  -1.3354,  -1.4152,\n",
      "           -0.6918,  -3.8428,  -3.6443,   1.0251,  -5.4843,   1.1073,   5.0811,\n",
      "           -5.9350,   0.4604,   2.9113,   0.4852,  -1.7763,   6.7567,  -5.1055,\n",
      "            5.0012,  -8.3242,   2.7466,   2.5176,   2.0208,  -5.7217,   1.9916,\n",
      "            1.2622,   6.0221,   9.4214,  -4.0864,   2.8967,   3.0174,  -1.1959,\n",
      "            1.7357,   8.1759,   1.6212,   7.2355,   2.0669,   1.2516,  -1.4059,\n",
      "            4.6549,  -0.4038,   2.9468,  -1.5464,  -0.1426,   1.9710,  -1.5866,\n",
      "           -5.5930,  -2.9847,   1.0734,   0.5412,   0.7043,   0.6288,   4.8763,\n",
      "            7.4709, -13.9306,  -0.0175,  -1.9858,  -0.3164]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x16988c0e0>\n",
      "<built-in method size of Tensor object at 0x152378770>\n",
      "tensor([[[ 0.6432,  0.3844, -1.9688,  0.3514,  0.1371, -1.4247, -0.5300,\n",
      "          -0.9247, -0.7646,  0.8670,  2.7150,  1.4282, -2.0843, -1.4179,\n",
      "           0.3017,  0.3184, -1.8962, -0.3716, -1.4901, -0.1296,  0.3184,\n",
      "          -0.1524,  0.0373,  0.6656, -0.7030, -1.8215,  0.2061,  0.2752,\n",
      "           0.4648,  0.3732,  0.4749,  0.5430,  0.9913, -0.5669,  0.8431,\n",
      "           0.9991, -1.0000,  0.9977, -0.9555, -0.1524,  0.9883, -0.9257,\n",
      "           0.9186,  0.9369,  0.8019, -0.9999, -0.9826, -0.9996, -1.0000,\n",
      "           0.9813,  0.7619, -0.9497,  0.9596, -0.9914, -0.9971, -0.9911,\n",
      "          -0.9999, -0.9796, -0.9927,  0.9673, -0.9999, -0.9761, -0.4006,\n",
      "           0.9904]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9540, -0.9990,  0.9287,  0.8130, -0.9997,  0.9086,  0.9966,\n",
      "          -0.1490,  0.1220,  0.8626,  1.0000, -0.2987, -0.9997,  0.1029,\n",
      "           0.9801,  0.1224,  0.1653,  0.8952,  0.0945,  0.2667, -0.9991,\n",
      "          -0.9986, -0.9993,  0.9450,  0.6439,  0.1875, -0.5144,  0.4449,\n",
      "           0.2568, -0.9668,  0.9361,  0.9813]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ -0.1680,  -1.5583,  -1.2877,   0.7651,   7.1636,   0.9820,  -1.4547,\n",
      "           -2.4890,  -1.4043,   9.4557,  -5.8153,  -1.4076,   0.9559,   2.1656,\n",
      "            0.2483,   2.5079,  -3.7142,   3.2530,   4.6259,   3.0375,   0.1561,\n",
      "           -2.7065,   3.4796,   4.1717,  -2.3340,   4.3890,   0.2353,  -4.8235,\n",
      "            4.3228,   2.3646,  -7.6200,   4.2298,   3.3874,  -0.7086,   6.3519,\n",
      "           -2.3574,  -1.7293,  -0.8844,  -3.2032,   0.7077,   1.3190,  -2.7577,\n",
      "           -0.9538,  -5.5726,   0.6260,  -5.4762,  -4.2977,   5.1565,   5.8224,\n",
      "           -5.2026,   5.1197,  -4.5394,   2.1461,   0.8123,   1.1081,   7.1700,\n",
      "           -1.3639,  -5.0631,   4.6432,  -5.0471,  -5.1938,   1.3228,   5.7099,\n",
      "           -1.6994,   0.6969,  -4.0990,  -2.0886,  -4.9831,   3.1422,  -2.7261,\n",
      "           -5.9148,  -3.8937,   0.0110,  -5.7539,  -1.8571,  -0.2461,  -0.2708,\n",
      "           -3.3985,  -5.5160,  -6.5241,  -2.3263,  -3.0366,   1.5740,  -1.7617,\n",
      "           -5.8940,   0.6843,  -1.7716,  -9.3508,   5.0101,   2.5120,  -4.6695,\n",
      "           -1.7773,  -2.2132,  -1.8254,  -2.9447,  -2.3771,  -6.9233,  -3.3440,\n",
      "           -0.4046,  -2.6420,  -4.4075,   0.1754,   3.9761,   1.8877,   6.0095,\n",
      "            2.5764,  -0.2717,   0.3575,  -0.7358,   2.6237,   1.7928,  -0.0608,\n",
      "            2.7977, -10.6548,  -0.8855,  -0.9311,  -0.9983,  -1.7808,   2.9000,\n",
      "           -4.5275,  -4.4720,  -4.2324,  -3.9630,  -7.5609,   3.6435,  -3.2308,\n",
      "           -4.5228,  -4.5325,  -7.9585,   0.8773,  -4.8880,  -6.4163,   2.5607,\n",
      "            2.3893,   0.3185,   3.4964,   4.1527,   7.9475,  -0.6227,  -4.6171,\n",
      "           -2.8305,  10.9542,  -5.5855,   1.3909,   2.3845,   2.2878,   1.7971,\n",
      "           -4.6293,  -4.4954,  -4.9825,   7.3698,  -4.2620,   7.1946,   1.6552,\n",
      "           -8.0091,  -4.7397,  -2.2455,  -1.2912,  -5.2992,  -5.5942,  -5.3472,\n",
      "           -2.4418,  -0.1974,   0.8943,   1.2565,   0.4648,   1.3915,   4.0891,\n",
      "           -3.8390,  -2.0267,   0.2289,  -6.1105,  -3.0386,  -2.8971,   3.6067,\n",
      "           -2.7998,   0.7870,  -3.0801,   0.1937,   0.3005,   5.6303,  -1.0763,\n",
      "            8.7525,   1.8199,  -1.6052,  -2.5622,  -6.1037,  -2.4385,  -1.9398,\n",
      "            7.7628,  -6.0137,  -1.5925,  -1.6516,   0.5321,   2.7056,  -3.5671,\n",
      "           -5.5121,  -7.9977,  -2.6800,   0.9484,  -2.0031]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x15251acc0>\n",
      "<built-in method size of Tensor object at 0x152378770>\n",
      "tensor([[[ 1.3597, -1.2280,  0.9861, -0.4837,  0.0231, -0.3062, -0.9334,\n",
      "           0.2566,  0.1067,  0.0412, -0.1155,  1.4916, -0.1961, -0.0212,\n",
      "           0.1775, -0.1087,  0.5356,  0.2766, -1.7448, -0.5524, -1.2818,\n",
      "           0.5919, -0.0729, -0.2654,  0.0382,  0.6538, -0.3230, -0.9120,\n",
      "          -0.8509,  0.9540,  1.5357,  1.3126,  0.9540, -0.9990,  0.9287,\n",
      "           0.8130, -0.9997,  0.9086,  0.9966, -0.1490,  0.1220,  0.8626,\n",
      "           1.0000, -0.2987, -0.9997,  0.1029,  0.9801,  0.1224,  0.1653,\n",
      "           0.8952,  0.0945,  0.2667, -0.9991, -0.9986, -0.9993,  0.9450,\n",
      "           0.6439,  0.1875, -0.5144,  0.4449,  0.2568, -0.9668,  0.9361,\n",
      "           0.9813]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[-0.8637, -0.4402,  0.3233,  0.8398, -0.5460,  0.9081,  0.9920,\n",
      "          -0.1453, -0.8619,  0.6055,  0.9492,  0.0850, -0.3094,  0.3407,\n",
      "           0.9994,  0.5326,  0.1089,  0.9525, -0.9885,  0.0328, -1.0000,\n",
      "          -0.9931, -0.9801, -0.1887,  0.8671,  0.8890,  0.0220,  0.5981,\n",
      "          -0.0632,  0.0607,  0.9997,  0.9935]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ 1.1061, -1.4687, -1.0838,  1.2762,  2.4242,  0.6665, -1.6896,\n",
      "          -5.6713, -0.5407,  8.9660, -0.2347,  0.3234, -4.2859,  0.5165,\n",
      "          -4.6546, -1.1130, -3.1476,  4.0632,  0.5573,  1.8389,  1.8164,\n",
      "          -0.7342,  0.1601,  2.7642,  3.2663,  4.6946, -0.0923, -3.1099,\n",
      "          -0.7321,  1.3590, -4.0935,  0.0976,  4.6679, -2.1929,  7.4413,\n",
      "          -1.9411, -3.6018, -2.8493, -2.7907,  0.5159,  4.2249, -1.6819,\n",
      "          -0.8675, -5.9858,  1.3886, -5.1146, -0.0701,  1.5311,  0.5652,\n",
      "          -2.7505,  4.9651, -4.4905,  3.7015,  1.1855,  2.0590,  1.3275,\n",
      "          -0.0351, -0.8383,  2.6866, -3.2735, -0.3612,  0.6788,  1.8676,\n",
      "          -4.1622, -1.5932, -0.9478, -0.9705, -3.8837,  3.3051, -2.7015,\n",
      "          -4.8633, -4.0889,  3.2748, -3.2137,  1.1010, -1.0283, -0.9291,\n",
      "          -4.2306, -3.6606, -1.1763, -2.6954, -3.2110,  1.4397, -0.4637,\n",
      "          -5.4028,  1.1363, -1.0692, -7.3073,  3.9588, -0.0982, -2.5648,\n",
      "          -2.7207, -3.1468, -2.3791, -0.3107, -0.2388, -3.1723,  0.4464,\n",
      "           1.5925,  1.0166, -6.8833,  1.6140,  0.9631, -0.3583,  7.0616,\n",
      "           4.7150,  3.7800,  3.6413,  2.2375,  0.1888,  0.3704, -0.2049,\n",
      "          -0.9638, -6.5286, -1.5498,  0.5489, -1.4786, -1.6349,  2.1156,\n",
      "          -4.7904, -3.3439, -2.8581, -3.2964, -4.0223, 10.2105, -0.3553,\n",
      "          -5.7113, -5.3588, -6.2809,  0.4311, -8.4955, -4.6120,  2.1977,\n",
      "           1.9192,  2.0487,  2.7998,  3.8433,  4.9554,  0.7655, -4.1834,\n",
      "          -2.4712,  8.2469, -4.0715,  4.5839,  4.9656,  5.0669,  5.0315,\n",
      "          -2.6267, -0.7169, -1.4908,  5.7935, -4.5490,  7.4303,  0.4165,\n",
      "          -6.4738, -4.9025, -1.4573, -2.8463,  1.4169, -4.6390, -0.4112,\n",
      "          -4.1721,  3.8474,  1.1550,  0.7651,  0.4884,  1.2457,  3.9088,\n",
      "          -2.5572, -1.9352,  0.5758, -8.0926, -3.3161, -3.2377,  5.1286,\n",
      "          -3.4159, -2.0226, -3.3618, -1.9298, -0.4136,  5.1750, -5.1805,\n",
      "           3.9972,  1.6181, -2.2934,  0.4280, -7.3923, -2.1343, -2.6362,\n",
      "           5.8281, -3.2766, -0.9788, -0.9478,  1.4706,  3.5908, -5.1466,\n",
      "          -6.5884, -5.5633, -1.2356,  2.0112,  2.5355]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x16988c0e0>\n",
      "<built-in method size of Tensor object at 0x15251a8b0>\n",
      "tensor([[[-0.8863, -0.7319,  0.0590,  1.3084,  0.4529, -1.0306,  0.8446,\n",
      "           0.0944,  0.8639,  1.2996, -0.4137, -1.2502,  1.2090, -0.5981,\n",
      "          -0.2339, -2.2033,  0.7436,  0.9228,  0.0054, -0.7296,  0.4351,\n",
      "          -0.3678, -2.8849,  0.1387,  1.3318,  0.3986,  0.8150,  0.7625,\n",
      "          -2.2552, -1.8282,  0.8439, -0.1134, -0.8637, -0.4402,  0.3233,\n",
      "           0.8398, -0.5460,  0.9081,  0.9920, -0.1453, -0.8619,  0.6055,\n",
      "           0.9492,  0.0850, -0.3094,  0.3407,  0.9994,  0.5326,  0.1089,\n",
      "           0.9525, -0.9885,  0.0328, -1.0000, -0.9931, -0.9801, -0.1887,\n",
      "           0.8671,  0.8890,  0.0220,  0.5981, -0.0632,  0.0607,  0.9997,\n",
      "           0.9935]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[-0.9339, -0.0066,  0.4417,  0.9867, -0.0135,  0.9069,  0.9395,\n",
      "           0.0476, -0.2755,  0.0098,  0.9481, -0.2478, -0.6319,  0.3709,\n",
      "           0.9944,  0.5717, -0.6146,  0.8467, -0.9956,  0.0669, -1.0000,\n",
      "          -0.9882, -0.8871,  0.2053,  1.0000,  0.9887,  0.1558,  0.6490,\n",
      "           0.1653,  0.9041,  1.0000,  0.9618]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ 3.6710e-02, -4.8732e-01,  1.4294e-01,  2.4724e+00,  7.5287e-01,\n",
      "          -2.1194e+00, -1.9072e+00, -5.9354e+00, -2.7371e+00,  1.1086e+01,\n",
      "          -6.3547e-01,  6.6207e-01, -4.1444e+00, -7.7830e-01, -2.8029e+00,\n",
      "          -2.6571e+00, -1.7699e+00,  3.8596e+00,  1.0815e+00, -6.2165e-01,\n",
      "           1.6558e+00, -9.5667e-01,  1.4705e+00,  1.8632e+00,  3.9014e+00,\n",
      "           4.5441e+00, -9.0092e-01, -2.4286e+00, -1.9579e+00, -1.7504e+00,\n",
      "          -4.4032e+00, -6.2947e-01, -5.5790e-01, -3.0981e+00,  7.4748e+00,\n",
      "          -6.7807e-01, -5.5619e+00, -2.8120e+00, -4.4957e+00,  5.9092e-02,\n",
      "           3.6507e+00, -5.2251e-01,  1.4523e-01, -4.1364e+00,  3.0231e+00,\n",
      "          -3.3739e+00,  2.1023e-01,  2.3627e+00,  1.8255e+00, -4.7502e-02,\n",
      "           3.7116e+00, -2.8707e+00,  3.5196e+00,  1.4986e+00,  4.5699e+00,\n",
      "           2.7304e+00,  6.6441e-01, -2.5720e-01,  2.1792e+00, -1.6899e+00,\n",
      "           1.3940e+00,  4.0841e-01,  1.6423e+00, -1.5916e+00, -2.8846e+00,\n",
      "           5.9442e-01,  3.1744e-01, -3.6723e+00,  2.0313e+00, -3.4945e+00,\n",
      "          -4.3582e+00, -3.4344e+00,  4.0497e-01, -2.9101e+00,  7.9294e-01,\n",
      "           5.1301e-01,  5.5107e-01, -2.7802e+00, -3.5138e+00,  4.7993e-01,\n",
      "          -1.9982e+00, -2.5319e+00,  5.8728e-01, -1.3247e+00, -5.6540e+00,\n",
      "           2.4063e+00, -1.0137e+00, -4.1063e+00,  4.7346e+00, -1.4732e+00,\n",
      "          -2.7065e+00, -4.1777e+00, -4.6312e+00, -2.0513e+00,  6.4181e-01,\n",
      "           7.2072e-01, -1.5618e+00,  1.1883e+00, -2.9585e-02,  6.0970e-01,\n",
      "          -7.4752e+00, -7.9064e-02,  1.9331e+00, -2.4874e+00,  5.4612e+00,\n",
      "           4.9026e+00,  5.3158e+00,  3.7819e+00,  2.0438e+00,  1.1384e+00,\n",
      "           3.6556e-02, -2.6307e+00, -5.2400e-01, -4.6254e+00, -2.2485e+00,\n",
      "           6.3904e-01, -1.2954e+00, -1.3499e+00,  1.0327e+00, -4.5091e+00,\n",
      "          -2.3244e+00, -3.0757e+00, -3.8881e+00, -4.0287e+00,  1.0734e+01,\n",
      "           4.5966e-01, -5.3621e+00, -5.0434e+00, -4.0689e+00,  1.1612e+00,\n",
      "          -7.3747e+00, -4.3535e+00,  1.2379e+00,  3.3489e+00,  2.3748e+00,\n",
      "           2.1838e+00,  3.8547e+00,  4.3446e+00,  8.6062e-04, -5.3425e+00,\n",
      "          -4.6307e+00,  8.3765e+00, -3.7877e+00,  4.3995e+00,  4.7626e+00,\n",
      "           4.8837e+00,  4.8620e+00,  8.5713e-01, -2.5292e-01, -9.3950e-01,\n",
      "           6.9643e+00, -4.3919e+00,  7.2520e+00, -1.0540e+00, -4.9313e+00,\n",
      "          -3.0220e+00, -1.0911e+00, -4.3687e-01,  2.3321e+00, -2.2005e+00,\n",
      "           3.7216e+00, -4.2177e+00,  4.6682e+00,  2.4279e+00,  1.9167e+00,\n",
      "           1.7174e+00,  1.5577e+00,  2.5527e+00, -1.9247e+00, -2.9267e+00,\n",
      "           9.6661e-01, -8.0078e+00, -2.2139e+00, -2.0099e+00,  5.3701e+00,\n",
      "          -1.8194e+00, -2.0147e+00, -1.6325e+00, -1.8399e+00,  1.0703e+00,\n",
      "           5.7637e+00, -5.6546e+00,  4.9537e+00,  7.3890e-01, -1.3449e+00,\n",
      "           6.0112e-01, -7.0212e+00, -1.6829e+00, -2.2714e+00,  7.3959e+00,\n",
      "          -2.7336e+00, -9.9440e-01, -1.2352e+00,  1.6272e+00,  4.5087e+00,\n",
      "          -4.5792e+00, -7.8370e+00, -3.5150e+00,  4.6925e-02,  5.0739e+00,\n",
      "           3.3569e+00]]], grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x15250ff40>\n",
      "<built-in method size of Tensor object at 0x16988c0e0>\n",
      "tensor([[[ 0.4952,  1.0615,  1.1364,  0.6482, -0.7819,  2.4550, -0.7107,\n",
      "          -1.5699, -2.5459, -2.1382, -1.1130,  1.8550,  0.6153,  0.4178,\n",
      "           2.0334,  1.1457,  1.5606, -2.4436,  2.5177,  0.8228,  0.2283,\n",
      "           1.1364, -0.5621, -1.0967,  0.6416,  0.0198,  1.7795, -1.8578,\n",
      "          -0.7997,  2.1149, -0.7998, -1.8135, -0.9339, -0.0066,  0.4417,\n",
      "           0.9867, -0.0135,  0.9069,  0.9395,  0.0476, -0.2755,  0.0098,\n",
      "           0.9481, -0.2478, -0.6319,  0.3709,  0.9944,  0.5717, -0.6146,\n",
      "           0.8467, -0.9956,  0.0669, -1.0000, -0.9882, -0.8871,  0.2053,\n",
      "           1.0000,  0.9887,  0.1558,  0.6490,  0.1653,  0.9041,  1.0000,\n",
      "           0.9618]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[-0.3109,  0.9168,  0.9530,  0.9999,  0.7712,  0.9081, -0.8370,\n",
      "           0.2195, -0.5280,  0.6426,  0.9281, -0.4904, -0.7538,  0.2469,\n",
      "           0.8985,  0.6975, -0.1481,  0.9663, -0.9996, -0.6684, -1.0000,\n",
      "          -0.9921,  0.9844,  0.9558,  0.2523,  0.3143,  0.1818,  0.9156,\n",
      "          -0.2397,  0.9866,  1.0000,  0.9804]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ -0.1666,  -1.3497,  -0.7544,  11.4906,   3.8522,  -0.9217,  -2.9109,\n",
      "           -5.2984,  -7.5005,  11.7527,  -0.5356,  -1.6726,  -3.5440,  -1.5402,\n",
      "            3.5454,  -1.9253,  -3.8907,   2.2328,  -0.6675,  -3.3797,  -1.7365,\n",
      "           -2.3465,   2.6851,  -5.5476,   0.2180,   2.8217,  -5.5305,   1.0679,\n",
      "           -2.9434,  -6.7279,  -4.4438,   0.5910,  -2.5023,   2.8089,   5.5825,\n",
      "           -0.6630,  -6.2182,  -4.7702,  -2.9191,  -2.9308,  -0.7041,  -0.9623,\n",
      "            0.2685,  -0.3040,   3.1018,  -3.1329,   0.6584,   3.7780,  -2.2756,\n",
      "           -2.7120,  -2.2495,   1.2944,   2.7545,   3.5305,   8.2976,   0.1596,\n",
      "            0.6972,   3.0503,   3.0212,  -3.9182,   1.8699,  -2.9287,  -1.7193,\n",
      "           -2.8407,  -4.6043,   1.9549,  -2.2162,  -5.4047,   0.1119,  -4.4582,\n",
      "           -4.8683,  -3.5088,  -0.8721,  -5.4459,   0.9615,  -3.3270,  -3.5038,\n",
      "           -1.4099,  -6.2738,  -0.9497,  -6.2181,  -6.0130,  -4.0253,   1.4004,\n",
      "           -3.7768,   2.0030,   0.8167,  -6.6416,  -0.8733,  -4.6737,  -6.2181,\n",
      "           -7.3947,  -7.4978,  -3.5993,  -4.1196,  -4.0052,  -2.2122,   3.0695,\n",
      "            1.1340,   2.0483,  -3.5019,   0.0660,   2.0052,  -0.5188,   2.8441,\n",
      "            4.1698,   7.0834,   6.2895,   2.9918,   2.8859,  -0.5976,  -2.3552,\n",
      "            5.2938,  -5.0048,  -3.0984,  -2.1796,  -0.6625,  -1.8354,   1.4533,\n",
      "           -4.1032,  -2.6250,  -5.6661,  -5.2243,   0.1179,   6.4634,   3.5987,\n",
      "           -2.4225,  -1.9702,  -3.7769,  -0.6820,  -2.2638,  -5.2701,   3.9797,\n",
      "            1.9290,   3.0932,   3.1510,   3.0705,   6.8786,   1.8095,  -4.4764,\n",
      "           -6.6174,   5.0655,  -5.7790,   0.0611,   0.5297,   0.3332,   0.4014,\n",
      "           -1.2599,  -0.7369,  -0.9121,   2.6523,  -7.2317,   3.5152,  -4.2056,\n",
      "           -3.6808,  -1.6590,  -1.3468,   2.6378,   3.0367,  -3.7783,   6.6660,\n",
      "           -2.9681,  -0.3521,   1.6304,   1.4527,   1.3351,   3.8631,   1.0041,\n",
      "            0.1097,  -5.5925,   2.2641, -11.6222,  -5.7828,  -5.4756,   2.7419,\n",
      "           -4.7575,  -3.3699,  -4.9182,  -3.4865,   3.4697,   3.5562,  -4.3225,\n",
      "            1.4564,   0.2963,   3.5458,   2.0486,  -9.6634,   1.5299,  -0.1435,\n",
      "            6.6524,  -0.8997,  -1.5714,  -1.7023,  -3.2724,   3.3159,  -9.0040,\n",
      "           -7.4266,  -5.3017,   0.5207,  -0.2737,  -0.6124]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x16988c0e0>\n",
      "<built-in method size of Tensor object at 0x152541c20>\n",
      "tensor([[[ 0.4952,  1.0615,  1.1364,  0.6482, -0.7819,  2.4550, -0.7107,\n",
      "          -1.5699, -2.5459, -2.1382, -1.1130,  1.8550,  0.6153,  0.4178,\n",
      "           2.0334,  1.1457,  1.5606, -2.4436,  2.5177,  0.8228,  0.2283,\n",
      "           1.1364, -0.5621, -1.0967,  0.6416,  0.0198,  1.7795, -1.8578,\n",
      "          -0.7997,  2.1149, -0.7998, -1.8135, -0.3109,  0.9168,  0.9530,\n",
      "           0.9999,  0.7712,  0.9081, -0.8370,  0.2195, -0.5280,  0.6426,\n",
      "           0.9281, -0.4904, -0.7538,  0.2469,  0.8985,  0.6975, -0.1481,\n",
      "           0.9663, -0.9996, -0.6684, -1.0000, -0.9921,  0.9844,  0.9558,\n",
      "           0.2523,  0.3143,  0.1818,  0.9156, -0.2397,  0.9866,  1.0000,\n",
      "           0.9804]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[-0.3160,  0.9904, -0.9486,  1.0000,  0.9298,  0.9284, -0.9929,\n",
      "           0.5272, -0.6778,  0.8366,  0.6300, -0.7780, -0.8094,  0.0308,\n",
      "           0.0409,  0.7175,  0.8917,  0.9542, -0.9999, -0.8689, -1.0000,\n",
      "          -0.9930,  0.9977,  0.9980,  0.1718, -0.9141,  0.5572,  0.2881,\n",
      "          -0.2551,  0.9061,  1.0000,  0.9835]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-1.7177e+00, -5.0293e-01, -2.3840e-01,  1.4096e+01,  6.7033e+00,\n",
      "          -8.6832e-01, -2.7350e+00, -5.6547e+00, -6.6764e-01,  8.2416e+00,\n",
      "          -4.3559e-01,  1.9283e+00, -4.8884e+00, -4.9930e+00,  3.4131e+00,\n",
      "          -1.7827e+00, -1.6757e+00,  2.0250e+00, -3.9236e+00, -3.0561e+00,\n",
      "          -2.2647e+00,  6.7912e-01,  1.2222e+00, -1.3767e+00, -2.2326e+00,\n",
      "           2.4346e+00, -5.3814e+00,  1.3849e+00, -1.5082e+00, -7.4445e+00,\n",
      "           1.0277e+00,  1.0330e-01,  3.8284e-01,  3.4064e+00,  2.8241e+00,\n",
      "          -3.9384e+00, -4.9889e+00, -5.3009e+00, -3.1404e+00, -2.0605e+00,\n",
      "           1.8833e+00, -4.0148e+00, -8.0452e-01,  1.2062e+00, -1.3171e+00,\n",
      "          -3.9335e+00, -1.4255e+00,  2.0874e+00, -4.2647e+00, -4.2638e+00,\n",
      "          -5.7411e+00,  4.1958e+00,  1.9340e-01,  5.7311e-01,  5.8092e+00,\n",
      "           1.2484e+00,  5.8467e-02,  3.7392e+00,  1.1291e+00, -4.8951e+00,\n",
      "           1.5004e+00, -2.6962e+00, -2.4548e+00, -3.7871e+00, -6.0687e+00,\n",
      "           3.0271e-01, -7.3050e+00, -2.7643e+00, -1.4564e+00, -5.0694e+00,\n",
      "          -3.3111e+00, -5.6283e+00,  2.5130e+00, -3.2789e+00, -7.9254e-01,\n",
      "          -6.4192e+00, -6.9331e+00,  1.8062e+00, -2.7963e+00, -3.0585e+00,\n",
      "          -4.5440e+00, -4.2590e+00, -4.5728e+00,  1.5632e+00, -3.2794e+00,\n",
      "           1.9840e+00,  2.8118e+00, -4.7785e+00, -4.2080e+00, -6.8361e+00,\n",
      "          -2.1143e+00, -6.9674e+00, -6.8500e+00, -8.0475e+00, -1.5440e+00,\n",
      "          -1.3453e+00, -1.1959e+00,  9.8371e-01,  1.1702e+00,  1.5088e+00,\n",
      "          -2.0599e+00, -8.4017e-01,  1.4801e+00, -1.0434e-01, -6.5637e-01,\n",
      "           3.4489e+00,  6.7913e+00,  7.6156e+00,  4.6466e+00,  4.4933e+00,\n",
      "          -1.9358e+00, -1.6363e+00,  5.0375e+00, -3.0092e+00, -4.0652e+00,\n",
      "           7.0639e-01,  1.4247e+00, -2.4118e+00,  1.6877e+00, -4.2682e+00,\n",
      "          -4.2013e+00, -3.6197e+00, -3.0656e+00,  2.3302e+00,  7.0794e+00,\n",
      "           8.2948e+00, -1.5910e+00, -1.2502e+00, -9.9907e-01, -3.1528e+00,\n",
      "          -7.4333e-01, -4.4838e+00,  2.1548e+00,  2.3805e+00,  3.6506e+00,\n",
      "           3.1490e+00,  2.0516e+00,  6.4144e+00,  3.6230e+00, -2.0342e+00,\n",
      "          -4.2693e+00,  2.7794e+00, -2.9318e+00, -1.0884e+00, -8.3634e-01,\n",
      "          -6.5946e-01, -9.9274e-01, -4.3191e+00,  7.9631e-01,  8.0479e-01,\n",
      "          -1.4990e+00, -8.4030e+00, -2.2102e-01, -3.4115e+00, -1.0212e+00,\n",
      "          -2.4093e+00, -2.1118e+00,  3.6755e+00,  4.8477e+00, -3.0233e+00,\n",
      "           5.7281e+00, -2.8211e+00,  1.1573e+00,  4.6325e-01,  4.5313e-01,\n",
      "           1.9784e-01,  4.6419e+00,  7.0330e-01,  2.1765e+00, -6.0039e+00,\n",
      "          -1.6156e+00, -9.0711e+00, -6.3341e+00, -5.5923e+00,  1.9505e+00,\n",
      "          -3.3298e+00, -3.1195e+00, -3.9402e+00, -3.3745e+00,  6.6167e+00,\n",
      "           2.8102e+00,  9.2531e-01, -2.7220e+00, -1.4917e+00,  1.4054e+00,\n",
      "           1.8852e+00, -7.4207e+00, -1.4107e-01, -1.1864e-01,  4.5308e+00,\n",
      "          -2.1023e+00, -3.6901e+00, -3.5314e+00, -3.2198e+00,  3.6365e+00,\n",
      "          -8.7088e+00, -2.3901e+00, -3.0349e+00, -8.5175e-03, -4.3242e+00,\n",
      "          -1.6161e+00]]], grad_fn=<PermuteBackward0>)\n",
      "he's calm . => sois détendu tard faire ? ?,  bleu 0.000\n",
      "<built-in method size of Tensor object at 0x152389400>\n",
      "<built-in method size of Tensor object at 0x1523b33b0>\n",
      "<built-in method size of Tensor object at 0x152378400>\n",
      "<built-in method size of Tensor object at 0x152378900>\n",
      "tensor([[[ 0.8106, -0.6988,  0.0032,  0.0862, -1.2587, -0.6633,  0.2425,\n",
      "           0.4189,  0.1711,  0.1278, -0.4198, -2.2580, -0.0491,  0.3116,\n",
      "          -1.7015, -1.4841, -1.0343,  1.1245,  0.9093, -0.2917,  0.1858,\n",
      "          -0.4663,  0.8404, -0.0680, -0.8339,  0.4894, -0.0552, -1.0674,\n",
      "          -0.5742, -0.0080,  1.4084,  0.8964, -0.9998, -0.9994, -0.9991,\n",
      "           0.9981,  0.9992, -0.9997, -0.9998, -0.1084, -1.0000, -0.8239,\n",
      "          -1.0000, -0.9952, -0.9869,  0.8987, -0.9754,  0.9999,  1.0000,\n",
      "           0.9955,  0.9827,  0.9834,  1.0000,  1.0000, -0.7908, -1.0000,\n",
      "          -1.0000,  1.0000, -0.9931,  0.9998,  0.9795, -0.8989, -0.6674,\n",
      "          -0.9999]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9971,  0.9997,  0.9999,  0.9981,  0.5626, -0.9997,  0.9407,\n",
      "           1.0000, -0.5541, -0.8239, -0.9998, -0.9947, -0.9810, -0.9138,\n",
      "          -0.9990, -0.3499,  0.9899,  0.9955,  0.9827,  0.9976,  0.9999,\n",
      "           1.0000, -0.8605, -0.9978, -1.0000,  0.9994,  0.9994,  0.9943,\n",
      "           0.9994, -0.8989, -0.6788, -1.0000]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ 5.5934e+00, -2.4364e+00, -2.2376e+00, -3.0695e+00, -6.4653e+00,\n",
      "          -4.7214e+00,  1.8620e+01,  2.2231e+00, -1.2622e+00, -5.6409e+00,\n",
      "           9.4426e+00,  4.7233e+00,  7.7704e+00,  6.8081e+00,  9.3416e-01,\n",
      "           1.1817e+00,  7.1688e-01, -4.9111e+00,  6.8286e+00, -1.3950e+00,\n",
      "           1.2575e+00,  7.0776e+00, -4.3065e+00,  1.9103e+00,  1.0616e+00,\n",
      "           1.9893e+00,  1.5102e+00,  6.4983e+00, -1.4075e+00,  1.7512e+00,\n",
      "          -5.8273e-01,  1.1817e+00, -8.3279e+00, -3.2654e-01, -4.0035e+00,\n",
      "           1.1511e+00, -1.2209e+00, -1.0146e-01,  1.1378e+01,  2.3231e+00,\n",
      "          -4.0749e+00,  1.0835e+00,  2.0611e+00, -3.9862e+00,  2.7330e+00,\n",
      "          -5.5083e+00, -1.6551e+00, -2.3362e+00,  5.1522e-01, -6.4555e-01,\n",
      "          -2.4432e+00, -3.2260e+00,  2.1812e+00, -2.5978e+00, -8.4101e+00,\n",
      "          -8.2266e+00,  2.0384e+00, -6.7190e+00, -3.6424e+00, -1.1595e+00,\n",
      "           5.0174e+00,  3.1297e+00, -2.1302e+00,  7.6647e+00,  6.1907e+00,\n",
      "          -2.3776e+00,  4.1184e+00, -3.2487e-01, -5.7881e+00,  2.5865e-02,\n",
      "          -2.6143e+00, -2.2335e+00, -7.7214e+00, -7.8344e-01,  5.4102e-01,\n",
      "           6.2792e+00,  6.2919e+00,  1.9684e+00, -2.4533e+00,  4.9397e+00,\n",
      "           5.1648e-01,  3.6487e-01, -4.4646e+00,  4.2535e+00,  3.9714e+00,\n",
      "           1.5922e+00,  5.5345e-01,  4.2067e+00, -3.0630e+00,  5.4303e+00,\n",
      "           2.9796e+00, -4.4625e+00, -4.3333e+00,  2.9425e+00,  2.4459e+00,\n",
      "           2.3804e+00,  1.2289e+00,  2.4659e+00,  5.8639e-02, -2.4062e+00,\n",
      "          -1.0223e+01,  5.7095e+00, -7.7183e-01, -3.1704e+00, -8.0183e+00,\n",
      "          -1.2206e+01,  2.4278e+00, -1.4975e+00, -1.3225e+00,  9.3517e-01,\n",
      "          -1.5212e+00,  6.8696e+00, -2.1297e+00, -6.6313e+00, -8.3172e-01,\n",
      "          -3.1629e+00, -9.8209e-01, -1.0438e+00, -4.9221e+00,  1.8383e+00,\n",
      "          -3.9385e+00, -2.8112e+00,  8.8766e-01,  8.7663e-01, -5.1427e+00,\n",
      "          -2.1706e+00,  5.8433e+00,  5.5713e+00, -6.0837e+00, -1.3586e+00,\n",
      "           3.1691e+00,  1.7179e-01, -8.0555e-01, -1.2920e+00, -4.3413e+00,\n",
      "           3.7381e-01,  2.8150e+00,  6.2981e-03,  9.7462e-01,  3.5701e+00,\n",
      "           1.1961e+00, -3.8066e+00, -2.7241e+00, -3.2892e+00, -2.7960e+00,\n",
      "          -3.5506e+00, -3.1779e+00,  5.8495e+00,  2.6939e-01,  5.0696e-01,\n",
      "           1.8649e+00, -1.8428e+00, -7.6908e-01, -3.1407e+00, -2.3539e+00,\n",
      "           4.3204e+00,  2.0956e+00, -6.0533e+00, -1.5489e+00,  1.1561e+00,\n",
      "          -4.3647e+00,  5.2309e+00, -2.5490e+00,  3.0163e+00,  2.3984e+00,\n",
      "           2.2539e+00, -1.7166e+00,  6.3556e-01,  1.1008e+00,  4.9849e+00,\n",
      "           1.3059e+00, -2.1221e+00,  8.9553e-01,  2.5029e-01,  7.8646e-01,\n",
      "           5.0818e+00, -1.9760e+00,  5.0633e+00, -1.7740e+00, -5.7116e-01,\n",
      "          -2.4648e+00,  3.9432e+00, -8.0308e-01,  5.0088e-01, -6.7271e+00,\n",
      "          -4.4816e+00, -4.2956e+00, -7.6803e+00, -3.2801e+00,  8.9187e-01,\n",
      "          -5.0967e+00, -2.4248e-01, -5.5797e-02, -5.3257e+00, -6.6664e+00,\n",
      "          -2.9548e-01, -6.9871e-01, -2.8797e+00,  1.6304e-03, -1.7895e+00,\n",
      "          -2.1842e-01]]], grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x152378770>\n",
      "<built-in method size of Tensor object at 0x152378400>\n",
      "tensor([[[-0.1749,  0.4951, -0.2640,  0.1415,  0.9820, -1.7539,  0.5951,\n",
      "           0.5392,  1.6357,  0.9578, -0.9413, -0.0287,  0.7417, -0.7564,\n",
      "          -0.1512,  0.3313,  0.5358,  0.7594,  1.9755, -0.0569,  0.2087,\n",
      "          -0.5678, -0.9687, -0.7058,  0.8887,  0.6302, -0.4276, -0.4136,\n",
      "          -0.7688,  0.9518, -2.4225, -0.1082,  0.9971,  0.9997,  0.9999,\n",
      "           0.9981,  0.5626, -0.9997,  0.9407,  1.0000, -0.5541, -0.8239,\n",
      "          -0.9998, -0.9947, -0.9810, -0.9138, -0.9990, -0.3499,  0.9899,\n",
      "           0.9955,  0.9827,  0.9976,  0.9999,  1.0000, -0.8605, -0.9978,\n",
      "          -1.0000,  0.9994,  0.9994,  0.9943,  0.9994, -0.8989, -0.6788,\n",
      "          -1.0000]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9969,  0.9428,  0.9895,  0.9977, -0.9574, -0.9994,  0.9977,\n",
      "          -0.6035, -0.6372, -0.8238,  0.9928, -0.9997,  0.7901,  0.0547,\n",
      "          -0.9990, -0.9992, -0.2632, -0.9884,  0.9826,  0.9951,  0.9998,\n",
      "           0.9998,  0.9907,  0.8742, -0.9722, -0.9998, -0.9773,  0.9940,\n",
      "          -0.9996, -0.9943, -0.6788,  0.9785]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ 1.3696e+00, -1.6281e+00, -1.6328e+00, -2.8047e+00, -1.4183e+00,\n",
      "          -1.1700e+00,  2.9924e+00,  2.0113e+01, -1.0346e+01, -3.4876e+00,\n",
      "          -1.2320e+00, -2.8865e+00, -2.7408e+00,  5.2738e+00,  1.0967e+00,\n",
      "           1.9674e+00,  6.7008e+00,  2.2928e+00, -8.6026e-01,  4.8612e+00,\n",
      "          -1.1807e-01, -5.1956e+00, -9.5067e+00,  7.8199e+00, -8.7730e-02,\n",
      "           1.9308e+00, -5.0695e-01,  7.8290e+00, -1.9132e+00, -3.0636e+00,\n",
      "          -8.2368e+00,  1.1548e+00, -3.9777e+00,  9.6236e+00, -2.9688e+00,\n",
      "          -3.8455e+00,  1.1490e+01,  1.9602e+00,  5.5954e+00,  2.6717e+00,\n",
      "          -4.7852e-01, -4.7199e+00,  4.7030e+00,  2.9377e+00,  3.2613e+00,\n",
      "           3.4485e+00,  8.3091e+00,  2.9364e+00,  7.0127e+00, -2.6732e+00,\n",
      "          -1.6883e-02,  3.5114e-01, -2.0347e+00,  2.0936e+00, -5.1673e+00,\n",
      "          -6.6227e-01,  3.7504e-01, -1.8061e+00, -3.9698e-01, -1.6884e+00,\n",
      "           1.0870e+00,  3.7842e+00,  5.5429e+00, -1.3245e+00,  1.4153e+00,\n",
      "          -8.8339e+00,  1.0099e+00,  2.8730e+00, -4.7019e+00,  2.1135e-01,\n",
      "          -9.1878e+00, -2.5606e+00, -3.6546e+00, -2.8817e+00, -1.5101e-01,\n",
      "           1.1904e+00,  1.9745e+00,  3.3863e+00, -5.2193e+00,  3.8108e+00,\n",
      "          -4.1219e+00, -3.6794e+00, -2.3554e+00,  1.8064e+00,  7.0610e+00,\n",
      "           1.7013e-01,  1.7483e+00, -5.8941e-02, -7.9526e+00,  2.3308e+00,\n",
      "          -4.6087e-01, -1.2501e+00, -9.1569e-01,  2.2243e+00, -4.1047e+00,\n",
      "          -4.1138e+00, -4.8180e-01,  1.3734e+00, -3.9255e+00, -4.0296e+00,\n",
      "           5.0787e+00,  9.4118e-01,  2.4842e+00,  7.3240e+00, -3.6846e+00,\n",
      "          -1.1084e+01, -1.8497e+00, -2.8595e+00, -2.9510e+00,  1.7954e+00,\n",
      "          -4.3627e+00,  1.9345e+00,  6.6770e+00, -5.2033e+00, -6.7592e+00,\n",
      "          -3.4374e+00,  1.1069e+00,  5.4479e-01, -1.1654e+00, -5.3725e+00,\n",
      "          -3.6207e+00, -3.1776e+00, -1.4989e+00,  4.7341e+00, -8.2936e+00,\n",
      "          -1.5338e+00, -2.6026e+00, -2.7414e+00,  3.9222e+00, -5.4816e-01,\n",
      "           3.6488e+00,  1.7235e+00, -6.4229e-02, -4.9601e+00, -4.0306e+00,\n",
      "           3.2274e+00,  5.2217e+00,  2.3897e+00, -4.1020e+00, -2.3341e+00,\n",
      "          -2.5345e+00, -6.4422e+00, -4.8417e+00, -3.0656e+00, -2.4768e+00,\n",
      "          -3.1506e+00, -3.2866e+00,  2.1253e+00, -2.9991e+00, -2.0385e+00,\n",
      "          -5.6928e+00,  5.1187e-01, -3.0139e+00, -5.8632e+00, -9.7239e-01,\n",
      "          -2.4067e-01,  1.0517e+01,  3.4277e+00, -4.9878e+00, -3.5309e-01,\n",
      "           2.3481e+00,  2.6789e+00, -1.8859e+00,  1.7083e+00,  1.8450e+00,\n",
      "           2.0608e+00,  3.5866e+00,  1.1868e+00, -1.5650e+00,  3.8263e+00,\n",
      "          -1.2414e+00, -1.8556e+00,  3.1800e+00,  3.2305e+00, -7.4322e+00,\n",
      "          -8.7842e-01,  5.6857e+00, -6.1962e-01,  4.8266e+00, -4.2308e+00,\n",
      "          -4.3781e+00,  2.8761e+00, -1.0702e+00,  8.2835e-01,  3.1765e+00,\n",
      "          -7.6504e+00, -1.1946e+00,  1.3124e+00,  4.7261e+00, -7.4031e-01,\n",
      "           3.2417e-01, -1.6868e+00, -1.7356e+00, -3.2221e+00, -7.0525e+00,\n",
      "           5.0667e+00,  5.7516e+00, -4.4518e+00,  3.0448e+00, -1.3038e+00,\n",
      "          -7.3484e+00]]], grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x15238dbd0>\n",
      "<built-in method size of Tensor object at 0x16988c0e0>\n",
      "tensor([[[ 1.3052,  1.3149,  0.3037, -0.1139, -0.0288,  0.2135,  1.7510,\n",
      "           0.3474, -0.3587, -1.0382, -1.0186, -0.7527, -0.0091, -0.2888,\n",
      "           0.4088,  0.7229, -0.4201, -1.2427, -1.1120, -0.6903,  0.0713,\n",
      "          -0.5296, -0.3309,  1.0541, -0.5184,  1.4489,  1.5832, -1.4131,\n",
      "           0.0109,  0.0524, -1.6082,  1.4196,  0.9969,  0.9428,  0.9895,\n",
      "           0.9977, -0.9574, -0.9994,  0.9977, -0.6035, -0.6372, -0.8238,\n",
      "           0.9928, -0.9997,  0.7901,  0.0547, -0.9990, -0.9992, -0.2632,\n",
      "          -0.9884,  0.9826,  0.9951,  0.9998,  0.9998,  0.9907,  0.8742,\n",
      "          -0.9722, -0.9998, -0.9773,  0.9940, -0.9996, -0.9943, -0.6788,\n",
      "           0.9785]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[-0.7644, -0.8617,  0.9999,  0.4129, -0.9572, -0.9660, -0.9924,\n",
      "          -0.4641, -0.6453, -0.8224,  0.9995, -0.9993, -0.5305, -0.9540,\n",
      "          -0.9988, -0.9992,  0.8100,  0.7774,  0.9775, -0.5028, -0.9078,\n",
      "          -0.7513, -0.9853,  0.0994, -0.9949, -0.9512, -0.9953,  0.9879,\n",
      "          -0.9508,  0.9210, -0.7834,  0.9971]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ 1.3924, -0.4197, -0.0344,  0.7057, -0.4459, -0.8840,  0.2141,\n",
      "           6.0129, -4.8056, -5.3400, -1.7410, -6.4580, -2.4017, -6.0938,\n",
      "           0.2425,  0.9359, -4.5859,  1.3737, -8.6508,  1.9561, -3.4492,\n",
      "          -3.9619,  1.7460,  3.3004, -6.8058,  0.0909, -4.6975,  0.0835,\n",
      "           8.1461, -1.1692, -2.0958,  1.8252,  3.8144, -2.6121,  2.5814,\n",
      "          -0.5120,  2.5586,  9.1319, -1.6371,  3.7278,  9.5010, -1.4395,\n",
      "          -6.1122, -3.0900,  2.1936, -2.9052,  2.1709,  7.8134,  1.4172,\n",
      "          -4.3827,  0.4516,  3.1243, -5.9802,  8.0423,  1.5638,  1.2305,\n",
      "           1.7971, -8.9601,  4.7458, -6.1528,  3.3272,  4.4890,  1.5832,\n",
      "           3.2924,  1.9781, -5.5110,  4.2031, -4.5194, -2.5133,  4.7350,\n",
      "          -5.9630,  2.8043, -2.3172, -7.5911,  2.7746,  3.2803,  4.1049,\n",
      "          -9.8647,  0.3013, -1.7126, -8.2473, -8.5257, -0.8621, -1.6662,\n",
      "          -1.4522,  7.2766,  8.0933, -1.5857, -0.3200,  1.4111, -3.5953,\n",
      "          -2.5270, -2.3835,  3.2892, -1.4888, -1.9141, -5.3697, -2.3320,\n",
      "          -2.9433, -2.9313, -1.7262,  3.3832,  5.1568,  4.4097,  2.1765,\n",
      "          -3.8516,  4.1833,  1.2071,  4.7249, -0.5202, -2.4792, -3.5497,\n",
      "           1.9836, -4.2621, -5.5786,  1.6742,  8.3455,  3.5491,  2.7298,\n",
      "          -0.8968,  1.0179,  0.1628, -0.3905, -3.6991, -0.1820, -2.7529,\n",
      "           1.8204,  1.6578,  5.6704,  5.9454,  4.0752,  1.0654,  3.1428,\n",
      "          -1.0466, -7.1452,  5.8655,  4.0489,  7.2590,  0.2690,  5.6350,\n",
      "           0.0448, -0.3724,  0.2196,  1.8869,  2.4370,  2.0277,  2.0270,\n",
      "          -2.2169,  0.0688,  0.4175,  2.4742, -6.9584,  0.8820, -2.6468,\n",
      "          -3.8486,  0.3193,  6.0017,  3.1021,  1.0430,  8.2664, -5.2396,\n",
      "           5.4279, -5.7956,  7.0834,  6.8247,  6.8029,  0.9066,  3.8868,\n",
      "           4.3198,  7.0684, -0.2669, -1.5482, -1.6617, -0.9975,  1.9087,\n",
      "          -3.8472,  2.1369, -3.1321,  1.3295,  2.1060,  1.4219,  5.0582,\n",
      "           1.0702, -2.6300, -3.1741,  0.3599,  0.7868,  3.0666,  1.8113,\n",
      "           5.7769, -0.7592,  4.8025,  5.0375, -0.4402,  0.8543,  0.6041,\n",
      "           6.0619, -9.5303, -1.4710, -0.4049, -1.9937]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x152142b30>\n",
      "<built-in method size of Tensor object at 0x16988c0e0>\n",
      "tensor([[[-2.4067,  0.5914, -1.0381,  0.0660, -1.1752,  0.6219, -0.0277,\n",
      "           0.3090,  0.8058,  0.0120,  1.4052, -0.2257, -0.5808, -0.7747,\n",
      "          -1.1402,  0.2438, -2.1258, -0.3399, -0.7731,  0.0173,  1.1678,\n",
      "          -0.0050, -0.7003, -0.3349, -0.4146, -1.8845, -0.4998,  0.4430,\n",
      "           0.2217,  0.3087, -0.2489,  0.1561, -0.7644, -0.8617,  0.9999,\n",
      "           0.4129, -0.9572, -0.9660, -0.9924, -0.4641, -0.6453, -0.8224,\n",
      "           0.9995, -0.9993, -0.5305, -0.9540, -0.9988, -0.9992,  0.8100,\n",
      "           0.7774,  0.9775, -0.5028, -0.9078, -0.7513, -0.9853,  0.0994,\n",
      "          -0.9949, -0.9512, -0.9953,  0.9879, -0.9508,  0.9210, -0.7834,\n",
      "           0.9971]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.9381, -0.9851, -0.9843, -0.0928, -0.2550, -0.4004,  0.1647,\n",
      "           0.8843, -0.9818,  0.9152,  0.5874, -0.9971, -0.6850, -0.8966,\n",
      "           0.6375, -0.8759,  0.5840,  0.7723,  0.9508, -0.8126, -0.8102,\n",
      "          -0.7565,  0.9431,  0.9789, -0.9412, -0.7794, -0.9586, -0.9886,\n",
      "          -0.7658,  0.4216,  0.9932,  0.9971]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-2.2278e+00, -8.6798e-02,  2.0873e-03,  7.4702e+00,  1.3768e+01,\n",
      "           2.3042e+00, -3.8045e+00, -5.2062e-01, -3.5189e+00,  3.8064e+00,\n",
      "          -4.3518e+00, -5.7545e-01, -2.6215e+00, -7.4905e+00,  1.3691e+00,\n",
      "          -1.1120e+00, -3.3221e+00,  1.3048e+00, -5.1378e+00,  1.1442e+00,\n",
      "          -8.7305e+00,  1.7535e-03,  2.8795e+00, -3.9912e+00, -1.1304e+01,\n",
      "           7.5855e-01, -7.1153e+00, -1.4618e+00,  5.3507e+00,  3.8353e+00,\n",
      "          -3.5063e+00, -3.2313e-01,  7.9167e+00,  1.0107e+00, -1.1948e+00,\n",
      "          -5.3987e+00,  2.7067e+00, -1.2995e-01, -4.0021e+00,  3.3456e-01,\n",
      "           7.2351e-01, -5.8276e+00, -5.3589e+00, -2.5675e+00, -1.3376e-01,\n",
      "          -7.5096e+00, -4.8345e+00,  5.5382e+00, -2.0154e+00, -7.9290e+00,\n",
      "          -5.7504e+00,  4.8157e+00, -9.4081e+00,  5.2419e+00,  5.5385e-01,\n",
      "           4.6361e+00, -1.0615e+00, -2.2022e+00, -4.6701e-01, -6.9685e+00,\n",
      "          -3.2724e+00,  5.6221e-01,  2.3962e+00,  1.9415e-01, -7.5092e-01,\n",
      "          -4.6396e+00, -4.1881e+00, -3.1017e+00, -5.2421e-01, -4.8286e+00,\n",
      "          -1.4510e+00,  1.0619e+00,  1.2945e+00, -4.4219e+00, -5.5005e-01,\n",
      "          -4.6175e+00, -4.7704e+00, -3.2026e+00,  9.4075e-01, -6.4625e+00,\n",
      "          -7.2793e+00, -7.3786e+00, -3.3517e+00, -4.4791e+00,  5.9975e-01,\n",
      "           1.4329e+00,  1.9857e+00, -4.3994e+00,  2.6636e+00, -2.1059e+00,\n",
      "          -5.7752e+00, -3.6344e-01, -6.4501e-01, -2.9560e+00, -2.4168e+00,\n",
      "          -1.5251e+00, -3.3936e+00, -5.3144e+00,  7.8362e-01, -4.0194e+00,\n",
      "           1.5137e+00, -6.2583e-01,  4.5501e+00,  4.4989e+00, -5.1145e-02,\n",
      "           3.1452e+00, -3.5290e+00,  2.0636e+00,  3.8386e+00,  6.0167e+00,\n",
      "          -3.3230e+00, -2.2553e+00,  5.4471e+00, -2.1353e+00, -5.4888e+00,\n",
      "          -1.3783e+00,  1.8766e+00, -3.8887e+00, -1.6162e+00, -6.2723e-01,\n",
      "          -7.1695e-01,  1.8585e+00,  2.4391e+00, -2.2503e+00,  1.3437e+00,\n",
      "           4.4263e+00, -1.9982e+00, -1.6681e+00,  3.0775e+00, -2.0270e+00,\n",
      "           2.5985e+00,  2.8733e+00, -2.9402e+00,  2.4751e+00, -1.7526e-01,\n",
      "           4.9131e+00,  1.8981e+00,  7.9108e+00, -2.4992e-01,  5.0772e+00,\n",
      "           3.1116e+00,  1.6329e+00,  7.2810e-01,  1.1253e+00,  2.0801e+00,\n",
      "           1.7206e+00,  1.1561e+00, -9.6387e+00,  1.4487e+00,  1.9926e+00,\n",
      "          -2.9585e+00, -6.8343e+00, -4.6435e-01,  1.8007e+00, -1.1188e+00,\n",
      "           1.3987e+00, -2.1105e+00,  8.4137e-01, -1.8820e+00,  1.7933e+00,\n",
      "          -4.3736e+00, -4.6528e-01, -8.8792e-01,  4.4592e-01,  7.7259e-01,\n",
      "           3.8405e-01,  6.3633e-02,  2.9616e+00,  8.0796e-01, -1.7516e+00,\n",
      "          -2.8412e+00, -5.3924e-01, -5.2674e+00, -5.2449e+00,  5.2919e-01,\n",
      "          -2.9817e+00,  8.5159e-01, -3.2134e+00,  4.1598e-01,  4.8658e+00,\n",
      "           9.8455e-01,  1.0247e+01,  4.2697e-01, -4.7240e+00, -2.6601e+00,\n",
      "          -8.5635e-01,  3.2439e+00, -1.2477e+00,  2.9333e+00,  5.2811e+00,\n",
      "          -1.1464e+00,  2.2666e+00,  2.8165e+00, -2.1497e+00,  2.1155e+00,\n",
      "          -9.7146e-01,  1.8761e+00, -3.6410e+00,  1.2346e-01, -2.0835e+00,\n",
      "          -6.7730e-01]]], grad_fn=<PermuteBackward0>)\n",
      "<built-in method size of Tensor object at 0x152555400>\n",
      "<built-in method size of Tensor object at 0x15251af40>\n",
      "tensor([[[-1.2208,  0.9683, -1.4363,  1.9375, -0.9508,  1.3620,  0.0077,\n",
      "          -0.9960, -2.6099, -0.8484, -1.1518,  1.4891,  1.2493,  3.0472,\n",
      "           1.0534, -0.8887, -0.0725, -1.7192,  1.5008, -0.1137, -0.4895,\n",
      "          -0.0465, -1.2658, -1.0220, -1.7588, -1.2856,  1.6190,  1.6343,\n",
      "          -1.1993,  0.7814, -0.8043, -0.0160,  0.9381, -0.9851, -0.9843,\n",
      "          -0.0928, -0.2550, -0.4004,  0.1647,  0.8843, -0.9818,  0.9152,\n",
      "           0.5874, -0.9971, -0.6850, -0.8966,  0.6375, -0.8759,  0.5840,\n",
      "           0.7723,  0.9508, -0.8126, -0.8102, -0.7565,  0.9431,  0.9789,\n",
      "          -0.9412, -0.7794, -0.9586, -0.9886, -0.7658,  0.4216,  0.9932,\n",
      "           0.9971]]], grad_fn=<CatBackward0>)\n",
      "tensor([[[ 0.6419, -0.5981, -0.9664,  1.0000, -0.0205,  0.5301, -0.0584,\n",
      "           0.8781, -0.9819,  0.1206, -0.9393, -0.9971, -0.7614, -0.8900,\n",
      "           0.8535, -0.8727,  0.3266,  0.7799, -0.9768, -0.9058, -0.9929,\n",
      "          -0.7445,  0.9901,  0.9999, -0.8148, -0.9213, -0.9362, -0.9613,\n",
      "          -0.7618,  0.9533,  1.0000,  0.9970]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[ -0.3615,  -0.5297,  -0.2580,  13.4989,   9.2604,   1.1794,  -4.1681,\n",
      "           -8.5659,  -6.4586,   5.5605,  -1.1209,   1.7904,  -7.5187,  -6.2081,\n",
      "            3.0919,  -1.9255,  -2.1729,   2.2042,  -3.5638,   0.1201,  -4.2208,\n",
      "           -0.3146,   2.4378,  -3.7914, -10.3929,   5.8224,  -5.6703,   0.0411,\n",
      "           -0.1668,  -2.1694,  -2.5086,   0.3710,   3.5931,  -0.9450,   2.7297,\n",
      "           -5.8173,  -0.7363,  -4.9814,  -6.6263,   1.9280,   4.1830,  -5.9714,\n",
      "           -1.2346,   1.7107,  -0.2521,  -6.0234,  -3.2557,   5.9254,  -1.0187,\n",
      "           -5.3660,  -5.8604,   3.7369,  -6.7170,   2.0318,   2.6853,   3.2096,\n",
      "            2.3240,  -3.7752,  -2.2860,  -4.5775,  -0.1314,   1.1624,   1.4679,\n",
      "           -3.8848,  -4.5724,  -2.8940,  -3.3149,  -2.5331,  -4.5643,  -3.6286,\n",
      "           -3.8238,  -0.6988,   0.5979,  -3.3074,  -4.7405,  -3.9254,  -3.9236,\n",
      "           -1.4737,   0.4260,  -5.9592,  -4.5813,  -4.7194,  -5.6320,  -2.3303,\n",
      "           -3.3270,   1.4154,   0.0885,  -6.4429,   0.8374,  -6.2273,  -6.1845,\n",
      "           -0.8035,  -0.8459,  -3.4952,  -0.6780,   0.0325,  -2.2137,  -2.7229,\n",
      "           -0.7204,  -1.6705,  -2.8380,   1.0239,   3.9992,   0.8938,  -1.7315,\n",
      "            3.5358,   1.4188,  -0.9064,  -0.9368,   1.4257,  -1.9122,  -2.2392,\n",
      "            4.2592,  -0.5403,  -5.7937,   1.7238,   1.9097,  -1.4595,  -1.8977,\n",
      "           -4.6923,  -0.9293,   0.7774,   1.1610,   1.1485,   5.2158,   4.6387,\n",
      "           -6.1442,  -5.5435,   2.7547,  -4.4901,   1.6560,  -0.9609,  -1.6800,\n",
      "            4.6100,  -1.2998,   2.6373,   0.1804,   5.1459,  -0.3447,   0.7535,\n",
      "           -0.3230,   2.8947,   0.3428,   1.6144,   2.3836,   2.1141,   1.8985,\n",
      "           -5.7661,   2.6728,   2.5138,  -2.9843,  -9.6155,  -1.8835,   1.0860,\n",
      "           -1.7952,  -1.1610,  -0.9343,   3.9475,   1.8541,   4.6471,  -0.3976,\n",
      "           -2.0578,  -0.9937,  -1.2405,  -1.1166,  -1.3645,  -0.1058,  -1.2817,\n",
      "            0.1497,  -4.8235,  -4.8736,  -6.7429,  -5.4443,  -5.3107,   4.8804,\n",
      "           -2.2959,  -1.1407,  -3.1001,  -1.2481,   4.0731,  -0.7692,   3.4927,\n",
      "           -2.8092,  -2.8988,  -0.8866,   3.9090,  -1.5326,  -4.0116,   1.0974,\n",
      "            3.4105,  -1.0345,   0.3395,   0.0755,  -2.6713,   4.6605,  -0.6489,\n",
      "            0.2929,  -5.2234,   1.0246,  -3.1132,  -2.3791]]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "i'm home . => je suis calme .,  bleu 0.512\n"
     ]
    }
   ],
   "source": [
    "for eng, fra in zip(engs, fras):\n",
    "    translation, attention_weight_seq = predict_seq2seq(\n",
    "        net, eng, src_vocab, tgt_vocab, num_steps, device)\n",
    "    print(f'{eng} => {translation}, ',\n",
    "          f'bleu {bleu(translation, fra, k=2):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
